{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rapid Implementation of Hardware Neural Networks Powered by Verython\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Introduction\n",
    "For our ECE 5760 final project, we built a Python to Verilog transpiler called ***Verython*** and then used it to implement a convolutional neural network (CNN) on the FPGA to classify handwritten digits. CNNs are among the most popular neural network architectures for image classification, as they have been shown to outperform humans in clinical imaging [(Source)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6586983/), and have a variety of recognition applications! Interestingly, CNNs behave like a black box: they ingest an input and generate an output without revealing their intrinsic logic. This project aimed to demystify CNNs by breaking their layers down into constituent components and implementing them in hardware. Additionally, we wanted to build a library that converts neural networks in Python (the most widely adopted language for machine learning) to Verilog with the hope of making high-performance computing more accessible to everyone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## TL;DR\n",
    "Here is a clip of Dr. Adams testing out our project:\n",
    "![video][hunter drawing inputs](https://www.youtube.com/watch?v=ZbLdQtHRYA0)\n",
    "\n",
    "Here is a sleep deprived-explanation of our project in the form of a video:\n",
    "![video][sleep deprived explanation](https://www.youtube.com/watch?v=LqQ_LQ5l_7k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## High-Level Design\n",
    "\n",
    "\n",
    "The term \"convolutional\" is derived from convolution's mathematical operation, which conventionally involves multiplying elements together and then summing them together. Therefore, the output of a convolution is a description of how the shape of one function influences another function. This unique property of our convolution is what our model captures: the spatial dependencies of an image. For our digit classification task, a conventional neural network would be overfitting to the specific location of the digit on the screen. In contrast, the convolutional layer would learn the edges and gradients of the image. \n",
    "\n",
    "The architecture of our network is as follows: a series of convolutional layers with max-pooling (twice), followed by a flattened, fully connected layer. Below is the TensorFlow (python library for building neural networks) summary of our model, highlighting all the trained parameters.  \n",
    "\n",
    "![image info](./images/tf.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following examples, we describe the high-level operations of each layer.\n",
    "\n",
    "Our convolutional layer uses a kernel size of $2\\times2$.  In this example, we output a $3\\times3$ feature map from a $4\\times4$ image.  Our $2\\times2$ filter slides from left to right across the image, accumulating the element-wise product summation.  We can extrapolate this result to $N\\times N$ images with $2\\times2$ kernels $\\to$ the output feature map will always be $(N-1)\\times(N-1)$, given that the kernel is sized $2\\times2$.  \n",
    "\n",
    "\n",
    "![image info](./images/conv.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a finishing touch to the output of our convolutional layer, we pass our values through a special function to “activate” or realize our predictions. Each element of the feature map gets passed through an activation function before moving on to the next layer. We initially chose the sigmoid activation function to keep our values between [0,1]. Extremely large positive values get normalized closer to 1, while large negative values get normalized closer to 0. We soon realized we needed many decimal bits in our fixed-point representation. We ended up resorting to ReLU activation, as the computational cost was cheaper and did not require significant decimal precision to activate values. In this activation function, negative values become zero while positive values retain their original value.\n",
    "\n",
    "![image info](./images/sigmoid.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Immediately following the convolutional layer is our max-pooling layer. Let’s take a 4x4 feature map as an example. Here, we use a pool size of 2x2 with a stride of 2. At each stride, we take the maximum element of the 2x2 window. This results in an output image of size 2x2. When the pool size is equal to the stride size, we effectively reduce the dimensions of the feature map by a factor of 2.  \n",
    "\n",
    "\n",
    "![image info](./images/mp.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, our fully-connected layer is the flattened output of the feature map. We connect it to our predicted digits of 0-9 and train our model to learn the weights of this layer. We can think of the weights as the strength of the connection. So, how much does the output depend on its connection? We take the dot product of the flattened feature map with each of their respective weights and pass them through another activation function to generate our predictions. We take the index of the element with the maximum probability in our ten-element vector array as our predictions for a given input.\n",
    "\n",
    "![image info](./images/fullyconnect.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Notation\n",
    "For some array $A$, let $A:[d1,\\dots,d_i,\\dots,d_n]$ indicate that that $A$ is $n$-dimensional and each dimension $1\\leq i\\leq n$ has a length of $d_i$. For example,\n",
    "$$A:[2, 3]=\\begin{bmatrix} a_{1, 1} & a_{1,2} & a_{1,3} \\\\ a_{2,1} & a_{2,2} & a_{2,3} \\end{bmatrix}.$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Introduction to Verython\n",
    "Complex structures such as neural networks comprise high-dimensional arrays and a large number of operations. Manually writing our model in Verilog would have been impossible under the three week time constraints--doing so would require tens of thousands of lines of handtyped Verilog. Instead, we wrote a Python library to write the Verilog for us. \n",
    "\n",
    "***[Verython](https://github.com/jfw225/verython)*** (portmanteau of Verilog and Python pronounced \"verithon\") is a Python to Verilog transpiler which generates Verilog modules from objects created in Python. Additionally, it interfaces directly with the free version of Intel's ModelSim to compile the Verilog, simulate the module's waveforms, and export that data back to Python where it compares the simulated data with the expected data computed in Python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- container: dark -->\n",
    "#### Syntax \n",
    "We start with the notion that lines of code in Verilog (or most languages for that matter) are simply sentences, and we can represent a sentence in Python as a `string`. Thus, if we can generate strings, we can generate Verilog. As we get into the structures in the library, you may notice the use of some types. These types are all defined in **Appendix B: Verython**, and we encourage the reader to reference the appendix in the case of confusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### V_Block\n",
    "The most fundamental object in ***Verython*** is the `V_Block` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python\n",
    "class V_Block(List[str]):\n",
    "    \"\"\"\n",
    "    The type representing a block of verilog code tabbed to the relative level.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *lines: List[str]):\n",
    "        super().__init__([V_Line(line) for line in lines])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `V_Block` object is essentially a list of `string` objects where each `string` is some line of Verilog code. For instance, the following `V_Block` instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python\n",
    "width = 4\n",
    "V_Block(\n",
    "    f\"wire [{width - 1}:0] w;\",\n",
    "    # `*` unpacks each of the strings in the list\n",
    "    *[f\"assign w[{i}] = 1'b1;\" for i in range(width)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generates the following verilog code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "verilog"
    }
   },
   "outputs": [],
   "source": [
    "# verilog\n",
    "wire [3:0] w;\n",
    "assign w[0] = 1'b1;\n",
    "assign w[1] = 1'b1;\n",
    "assign w[2] = 1'b1;\n",
    "assign w[3] = 1'b1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, this alone is nothing special, but it provides an easy, readible way to group lines of code and rapidly generate a large amount of Verilog. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Core Blocked Syntax\n",
    "Since Verilog can be represented by a group of `string` objects, we can represent each of Verilog's core blocked syntax as `V_Block` objects. Here we will show the ***Verython*** version of Verilog Always and If/Else statements, but the rest of the core blocked syntax can be seen in **Appendix B: Verython**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python\n",
    "def V_Always(\n",
    "    edge: V_PosEdge or V_NegEdge,\n",
    "    signal: V_Expression or V_Port or V_Variable\n",
    "):\n",
    "\n",
    "    def build(*lines: V_Block) -> V_Block:\n",
    "        return V_Block(\n",
    "            f\"always @ ({edge()} {signal.name}) begin\",\n",
    "            *[f\"\\t{line}\" for line in lines],\n",
    "            \"end\"\n",
    "        )\n",
    "\n",
    "    return build\n",
    "    \n",
    "def V_If(\n",
    "    predicate: V_Expression or V_ObjectBase\n",
    "):\n",
    "\n",
    "    assert isinstance(predicate, (V_Expression, V_ObjectBase)\n",
    "                      ), f'\"{predicate}\" is not a valid predicate.'\n",
    "\n",
    "    def build(*lines: Iterable[V_Line]) -> V_Block:\n",
    "        return V_Block(\n",
    "            f\"if ({predicate}) begin\",\n",
    "            *[f\"\\t{line}\" for line in lines],\n",
    "            \"end\"\n",
    "        )\n",
    "\n",
    "    return build\n",
    "\n",
    "\n",
    "def V_Else(\n",
    "    *lines: Iterable[V_Line]\n",
    ") -> V_Block:\n",
    "\n",
    "    return V_Block(\n",
    "        f\"else begin\",\n",
    "        *[f\"\\t{line}\" for line in lines],\n",
    "        \"end\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the blocked syntax overloads return `V_Block` object, and since a `V_Block` object inherits all of the properties of a Python list, we can use the `*` operator to unpack a `V_Block` into another `V_Block`. For instance, the following two examples are equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python\n",
    "V_Block(\n",
    "    \"wire clk;\",\n",
    "    \"reg [3:0] w;\",\n",
    "    *V_Always(V_Posedge, \"clk\")(\n",
    "        *V_If(\"w == 4'd0\")(\n",
    "            \"w <= 4'd1;\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    ") # is equivalent to\n",
    "\n",
    "V_Block(\n",
    "    \"wire clk;\",\n",
    "    \"reg [3:0] w;\",\n",
    "    \"\".join(*V_Always(V_Posedge, \"clk\")(\n",
    "        \"\".join(V_If(\"w == 4'd0\")(\n",
    "            \"w <= 4'd1;\"\n",
    "        ))\n",
    "    ))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated Verilog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "verilog"
    }
   },
   "outputs": [],
   "source": [
    "# verilog\n",
    "wire clk;\n",
    "reg [3:0] w;\n",
    "always @(posedge clk) begin\n",
    "    if (w == 4'd0) begin\n",
    "        w <= 4'd1;\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of ***Verython*** syntax can be combined in `V_Block` objects to create complex, powerful structures that would be very tedious and cumbersome to manually write in Verilog. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<!-- container: default -->\n",
    "#### Objects \n",
    "Up until now, you may have noticed that number, wire, and register definitions usage were manually typed in Python `string` objects. However, this disappears with the introduction of ***Verython*** objects.\n",
    "\n",
    "##### V_Int and V_FixedPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python\n",
    "class V_Int(V_Expression):\n",
    "    \"\"\" full implementation not shown \"\"\"\n",
    "\n",
    "class V_FixedPoint(V_Expression):\n",
    "    \"\"\" full implementation not shown \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instances of `V_Int` and `V_FixedPoint` objects keep track of the required bit widths. This is used by ***Verython*** to convert these instances to the proper Verilog format and add an additional layer of error checking before compilation. In addition, Python allows the developer to overload each of the standard library operators for an object. We leveraged this to make the following equivalence possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python\n",
    "a = V_Int(1, width=4)\n",
    "b = V_FixedPoint(1, int_width=1, dec_width=3)\n",
    "\n",
    "V_Block(\n",
    "    \"wire [3:0] a, b;\",\n",
    "    f\"assign a = {a};\", \n",
    "    f\"assign b = {b};\"\n",
    ") # is equivalent to \n",
    "\n",
    "V_Block(\n",
    "    \"wire [3:0] a, b;\",\n",
    "    \"assign a = 4'b0001;\",\n",
    "    \"assign b = 4'b1_000;\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated Verilog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "verilog"
    }
   },
   "outputs": [],
   "source": [
    "# verilog\n",
    "wire [3:0] a, b;\n",
    "assign a = 4'd1;\n",
    "assign b = 4'b1_000;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### V_Port, V_Variable, and V_Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python\n",
    "class V_ObjectBase:\n",
    "    \"\"\" full implementation not shown \"\"\"\n",
    "\n",
    "class V_Port(V_ObjectBase):\n",
    "    \"\"\" full implementation not shown \"\"\"\n",
    "\n",
    "class V_Variable(V_ObjectBase):\n",
    "    \"\"\" full implementation not shown \"\"\"\n",
    "\n",
    "class V_Array(V_ObjectBase, metaclass=V_ArrayMeta):\n",
    "    \"\"\" full implementation not shown \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Verython*** also has an object representation of Verilog ports, wires, registers, and arrays. Similar to `V_Int` and `V_FixedPoint`, each of the ***Verython*** objects defined above keep track of bit widths and have their default Python operators overloaded. This enables the  ***Verython*** to make the following transcompilation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python\n",
    "a = V_Int(1, width=4)\n",
    "b = V_FixedPoint(1, int_width=1, dec_width=3)\n",
    "\n",
    "pclk = V_Port(module=None,\n",
    "              port_type=V_Input,\n",
    "              name=\"clk\")\n",
    "preset = V_Port(module=None,\n",
    "                port_type=V_Input,\n",
    "                name=\"reset\")\n",
    "\n",
    "pcounter = V_Port(module=None,\n",
    "              port_type=V_Output,\n",
    "              dtype=V_Reg,\n",
    "              width=2,\n",
    "              name=\"counter\")\n",
    "\n",
    "wa = V_Variable(module=None,\n",
    "                dtype=V_Wire,\n",
    "                width=4,\n",
    "                name=\"example_wire\")\n",
    "\n",
    "rb = V_Variable(module=None,\n",
    "                dtype=V_Reg,\n",
    "                width=4\n",
    "                signed=True,\n",
    "                name=\"example_reg\")\n",
    "\n",
    "arc = V_Array(module=None,\n",
    "              dtype=V_RegArray,\n",
    "              width=4,\n",
    "              size=2,\n",
    "              name=\"example_array\")\n",
    "\n",
    "V_Block(\n",
    "    \"module count_to_four(\",\n",
    "    pclk, preset,\n",
    "    pcounter,\n",
    "    \");\",\n",
    "    wa, rb, arc,\n",
    "\n",
    "    *V_Always(V_PosEdge, pclk)(\n",
    "        *V_If(preset)(\n",
    "            pcounter.set(0)\n",
    "\n",
    "            rb.set(0),\n",
    "\n",
    "            arc[0].set(a),\n",
    "            arc[1].set(b),\n",
    "\n",
    "        ), *V_Else(\n",
    "            pcounter.set(pcounter + 1),\n",
    "\n",
    "            rb.set(rb + 1),\n",
    "\n",
    "            arc[rb].set(wa)\n",
    "        ),\n",
    "\n",
    "        *V_If(rb + 1 == 2)(\n",
    "            rb.set(0)\n",
    "        )\n",
    "    ),\n",
    "\n",
    "    wa.set(rb),\n",
    "    \"endmodule\"\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated Verilog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "verilog"
    }
   },
   "outputs": [],
   "source": [
    "# verilog\n",
    "module count_to_four(\n",
    "    input clk, reset,\n",
    "    output reg [1:0] counter\n",
    ");\n",
    "    wire [3:0] example_wire;\n",
    "    reg signed [3:0] example_reg;\n",
    "    reg [3:0] example_array [1:0];\n",
    "\n",
    "    always @(posedge clk) begin\n",
    "        if (reset) begin\n",
    "            counter <= 2'd0;\n",
    "            \n",
    "            example_reg <= 4'd0;\n",
    "\n",
    "            example_array[0] <= 4'd1;\n",
    "            example_array[1] <= 4'b1_000;\n",
    "        end else begin\n",
    "            counter <= counter + 2'd1;\n",
    "\n",
    "            example_reg <= example_reg + 4'd1;\n",
    "\n",
    "            example_array[example_reg] <= example_wire;\n",
    "        end\n",
    "\n",
    "        if (example_reg + 4'd1 == 4'd2) begin\n",
    "            example_reg <= 4'd0;\n",
    "        end\n",
    "    end\n",
    "\n",
    "    assign example_wire = example_reg;\n",
    "\n",
    "endmodule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<!-- container: dark -->\n",
    "#### Modules\n",
    "\n",
    "If you were at all concerned that you were going to have to manually write out the module header and footer, let me put your mind at ease. ***Verython*** also enables you to write Verilog modules entirely in Python. For the full implementation, look at **Appendix B: Verython**.\n",
    "\n",
    "[V_Module](https://github.com/jfw225/mnist-cnn-fpga/blob/main/src/python/verilog/core/vmodule.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python\n",
    "class V_Module:\n",
    "    \"\"\"\n",
    "    The base class for a verilog module.\n",
    "    \"\"\"\n",
    "\n",
    "class V_Iterable(V_Module):\n",
    "    \"\"\"\n",
    "    An object that implements an iterable verilog data structure. \n",
    "\n",
    "    Attributes:\n",
    "        `clk` -- 1-bit input signal\n",
    "            The port connecting this module to the clock line.\n",
    "\n",
    "        `reset` -- 1-bit input signal\n",
    "            The port that enables the caller to reset this module. \n",
    "\n",
    "        `write_en` -- 1-bit input signal\n",
    "            When this signal is HIGH, the data loaded onto `write_data` is \n",
    "            stored in memory at address `write_addr`.\n",
    "\n",
    "        `read_addr` -- (ceil(log2(size)))-bit input signal\n",
    "            The address from which data is read.\n",
    "\n",
    "        `write_addr` -- (ceil(log2(size)))-bit input signal\n",
    "            The address to which data is written.\n",
    "\n",
    "        `read_data` -- (width)-bit output signal\n",
    "            The data line into which data is read from memory at address \n",
    "            `read_addr`.\n",
    "\n",
    "        `write_data` -- (width)-bit input signal\n",
    "            The data line which is written to memory at address `write_addr`.\n",
    "    \"\"\"\n",
    "\n",
    "class V_Target(V_Module):\n",
    "    \"\"\"\n",
    "    The implementation of a module that can be used as the target \n",
    "    function in any module. \n",
    "\n",
    "    Attributes:\n",
    "        `clk` -- 1-bit input signal\n",
    "            The port connecting this module to the clock line.\n",
    "\n",
    "        `reset` -- 1-bit input signal\n",
    "            The port that enables the caller to reset this module. \n",
    "\n",
    "        `valid` -- 1-bit input signal\n",
    "            The port that indicates whether or not the input data is valid. The\n",
    "            caller can manipulate this signal to indicate whether or not the \n",
    "            input data is valid.\n",
    "\n",
    "        `done` -- 1-bit output signal\n",
    "            The port indicating whether or not the target function has finished \n",
    "            computation for a given input. When this flag is `HIGH`, the output \n",
    "            data is valid. Thus, the target module should raise this signal \n",
    "            when it finishes its task.\n",
    "\n",
    "        `ready` -- 1-bit output signal\n",
    "            The port indicating whether or not the target module is ready \n",
    "            to begin a task. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, we will show a ***Verython*** implementation of an M10K block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python\n",
    "class M10K(V_Iterable):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        width: BitWidth,\n",
    "        size: ArraySize,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(width, size, **kwargs)\n",
    "\n",
    "        self.memory = V_Array(self, V_RegArray, self.width,\n",
    "                              self.size, name=\"memory\")\n",
    "\n",
    "        self.syn_style = '/* synthesis ramstyle = \"no_rw_check, M10K\" */'\n",
    "\n",
    "    def generate(self):\n",
    "\n",
    "        mem_fmt_base, *_ = self.memory.define().split(\";\")\n",
    "\n",
    "        return V_Block(\n",
    "            \"// force M10K ram style\",\n",
    "            f'{mem_fmt_base} {self.syn_style} ;'\n",
    "            \"\\n\",\n",
    "            *V_Always(V_PosEdge, self.clk)(\n",
    "                *V_If(self.write_en)(\n",
    "                    self.memory.set(self.write_addr, self.write_data)\n",
    "                ),\n",
    "                self.read_data.set(self.memory.get(self.read_addr))\n",
    "            )\n",
    "        )\n",
    "\n",
    "M10K(width=16, size=784).generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated Verilog from an instance of `M10K` with `width=16` and `size=784`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "verilog"
    }
   },
   "outputs": [],
   "source": [
    "# verilog\n",
    "module M10K(\n",
    "\tinput    clk,\n",
    "\tinput    write_enable,\n",
    "\tinput   [9:0] read_addr,\n",
    "\tinput   [9:0] write_addr,\n",
    "\toutput reg  [15:0] read_data,\n",
    "\tinput   [15:0] write_data\n",
    ");\n",
    "\t// force M10K ram style\n",
    "\treg  [15:0] memory [783:0]  /* synthesis ramstyle = \"no_rw_check, M10K\" */;\n",
    "\n",
    "\talways @ (posedge clk) begin\n",
    "\t\tif (write_enable) begin\n",
    "\t\t\tmemory[write_addr] <= write_data;\n",
    "\t\tend\n",
    "\t\tread_data <= memory[read_addr];\n",
    "\tend\n",
    "endmodule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<!-- container: default -->\n",
    "#### States and State Machines\n",
    "The final piece of the architecture that we'll discuss in this elaborate introduction is ***Verython*** state machines. \n",
    "\n",
    "\n",
    "##### V_State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python\n",
    "class V_State(metaclass=_V_State_Meta):\n",
    "    \"\"\"\n",
    "    The object representing a state in a verilog state machine.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, state_id: V_StateID, width: BitWidth) -> None:\n",
    "        self.state_id = state_id\n",
    "        self.width = width\n",
    "\n",
    "    def generate(self, m: V_Module) -> V_Block:\n",
    "        \"\"\"\n",
    "        This function comprises the state logic: both what is done in the state\n",
    "        and how the state transitions. The return value should be some verilog\n",
    "        code and at least one state. The state machine will iterate through\n",
    "        the returned list of code and replace each `Type[V_State]` with an\n",
    "        assignment to change the state value. This should be overloaded.\n",
    "\n",
    "        If no state is found, the next state will be `V_StDone` and the\n",
    "        module's `done` flag will be raised.\n",
    "\n",
    "        The parameter `module` is the `V_Module` object in which this state\n",
    "        will be used.\n",
    "        \"\"\"\n",
    "\n",
    "        return V_Block(\n",
    "            *V_If(V_Expression(format_int(V_High, 1)))(\n",
    "                V_State\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "class V_StateMachine:\n",
    "    \"\"\" \n",
    "    Verilog implementation of a finite state machine.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        reset_state: Type[V_State],\n",
    "        *states: Iterable[Type[V_State]]\n",
    "    ) -> None:\n",
    "\n",
    "        # determine bit width needed for a state variable\n",
    "        # (+ 1 is for `V_StDone`)\n",
    "        self.width = BitWidth(ceil(log2(len(states) + 1)))\n",
    "\n",
    "        # set the reset state\n",
    "        self._reset_state = reset_state(\n",
    "            state_id=V_StateID(0), width=self.width)\n",
    "\n",
    "        # maps class types to initialized objects\n",
    "        self._state_map: Dict[NetName, V_State] = {\n",
    "            str(state): state(state_id=V_StateID(i), width=self.width)\n",
    "            for i, state in enumerate(states)\n",
    "        }\n",
    "\n",
    "    def generate(\n",
    "        self,\n",
    "        module: V_Module,\n",
    "        clk: V_Clock,\n",
    "        reset: V_Reset,\n",
    "        done: V_Done,\n",
    "        edge: Optional[V_PosEdge or V_NegEdge] = V_PosEdge\n",
    "    ) -> V_Block:\n",
    "        \"\"\"\n",
    "        This function generates a verilog state machine from `self._state_map` \n",
    "        that operates on the edge `edge of clock `clk`.\n",
    "\n",
    "        Each state has a `generate` function that should return an iterable \n",
    "        containing lines of verilog and at least `V_State` object. If no \n",
    "        `V_State` object is found, an error will be thrown.  \n",
    "\n",
    "        This function will create a state variable `state` in the verilog \n",
    "        module `module`, and will assign each of the states a value. We will \n",
    "        initialize `state` to `self._start_state` when `reset` is HIGH. \n",
    "\n",
    "        Let `V_i` denote the value assigned to the `i`-th state `S_i`. Then this \n",
    "        function will search through the iterables returned from each of the \n",
    "        `V_State.generate` calls and replace each `S_i` with `state <= V_i`.\n",
    "\n",
    "        The state machine will continue to run until `V_StDone` is \n",
    "        reached--at which point, the state machine will raise `done` and idle \n",
    "        until `reset` is set.\n",
    "        \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "States in any sort of finite state machine usually have two roles: do something and transition to a state. \n",
    "\n",
    "The \"do something\" component is accomplished by providing each state with the module `m` that implements the state machine. Doing so gives the state access to all of the modules ports, variables, and instances. \n",
    "\n",
    "The transition part is a little tricky. Suppose when you make your state machine, you want some state $a$ to transition to some other state $b$, and once you get to $b$, you want to go back to $a$. This is implemented in the following pseudocode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python\n",
    "class StateA:\n",
    "    def __init__(self, state_b):\n",
    "        self.state_b = state_b\n",
    "\n",
    "    def transition(self):\n",
    "        do_something()\n",
    "\n",
    "        go_to_state(self.state_b)\n",
    "\n",
    "class StateB:\n",
    "    def __init__(self, state_a):\n",
    "        self.state_a = state_a\n",
    "\n",
    "    def transition(self):\n",
    "        do_something()\n",
    "\n",
    "        go_to_state(self.state_a)\n",
    "\n",
    "state_a = StateA(state_b=None)\n",
    "state_b = StateB(state_a=state_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well $a$ and $b$ are really referring to instances of some state object. Suppose you create $a$ first. Well $a$ needs to have a reference to $b$, but $b$ hasn't been instansiated yet. Same logic applies if you create $b$ first. We solve this issue by instead referencing states by their static type rather than their instance. And then at transpile-time, the `V_StateMachine` object creates some `state` register, assigns each referenced state type some number `n`, and replaces the static reference with `state <= n` inside of an always block. Our example above becomes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python\n",
    "class OnReset(V_State):\n",
    "    def generate(self, m: V_Module) -> V_Block(\n",
    "\n",
    "        return V_Block(\n",
    "            do_something(),\n",
    "\n",
    "            StateA\n",
    "        )\n",
    "    )\n",
    "\n",
    "class StateA(V_State):\n",
    "    def generate(self, m: V_Module) -> V_Block(\n",
    "\n",
    "        return V_Block(\n",
    "            do_something(),\n",
    "\n",
    "            StateB\n",
    "        )\n",
    "    )\n",
    "\n",
    "class StateB(V_State):\n",
    "    def generate(self, m: V_Module) -> V_Block(\n",
    "\n",
    "        return V_Block(\n",
    "            do_something(),\n",
    "\n",
    "            StateA\n",
    "        )\n",
    "    )\n",
    "\n",
    "# notice the state parameters are not instances, they are static types\n",
    "V_StateMachine(OnReset, StateA, StateB).generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated Verilog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "verilog"
    }
   },
   "outputs": [],
   "source": [
    "# verilog\n",
    "reg [1:0] state;\n",
    "\n",
    "always @(posedge clk) begin\n",
    "    if (reset) begin\n",
    "        // do something\n",
    "\n",
    "        // go to StateA\n",
    "        state <= 2'd0;\n",
    "    end\n",
    "    else begin \n",
    "        case (state)\n",
    "            // StateA\n",
    "            2'd0: begin\n",
    "                    // do something\n",
    "\n",
    "                    // go to StateB\n",
    "                    state <= 2'd1;\n",
    "                end\n",
    "            \n",
    "            // StateB\n",
    "            2'd1: begin\n",
    "                    // do something \n",
    "\n",
    "                    // go to StateA\n",
    "                    state <= 2'd0;\n",
    "                end\n",
    "        endcase\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining the tools provided in the ***Verython*** library enables the rapid creation of robust and expansive Verilog code. In fact, let's talk about how we used it to do just that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program/Hardware Design\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Implementation\n",
    "In this section, we will dive deep into the math behind each of the layers in the model and how we rederived the transformation functions of each layer to fit on the FPGA. \n",
    "\n",
    "As a reminder, our model ingests some image of a hand-drawn digit and outputs a number between 0 and 9 which corresponds to the prediction of the model. The image is a 28 by 28 2D array of values between 0 and 255, or rather, some input image $img$ can be represented as\n",
    "$$img:[n=28,n]=\\begin{bmatrix} \n",
    "  p_{1,1} & \\dots & p_{1,j} & \\dots & p_{1,28} \\\\ \n",
    "  \\vdots & \\ddots & & & \\vdots \\\\\n",
    "  p_{i, 1} & \\dots & p_{i, j} & \\dots & p_{i, 28} \\\\\n",
    "  \\vdots & & & \\ddots & \\vdots \\\\\n",
    "  p_{28, 1} & \\dots & p_{28, j} & \\dots & p_{28, 28}\n",
    "\\end{bmatrix}$$\n",
    "such that $0\\leq p_{i,j}\\leq255$. \n",
    "\n",
    "Moreover, we can think of our model $M$ as a function that maps some input $img$ to some output prediction $pred$, or rather, the inference of our model can be represented by \n",
    "$$M(img)=pred$$\n",
    "for some output prediction $0\\leq pred\\leq9$. \n",
    "\n",
    "Furtheremore, we can also express each of the layers in our model as a a function. Let $L=\\{L_1,\\dots,L_i,\\dots,L_4\\}$ be the layers in our model. Then we can represent each layer $L_i$ as  \n",
    "$$L_i(V_i^{in})=V_i^{out},$$\n",
    "where $V_{in}$ and $V_{out}$ are matrices whose shapes are defined by $L_i$. \n",
    "\n",
    "Without loss of generality, each layer $L_i$ has associated weights $W^i$ and biases $B^i$. These parameters are applied to $V_i^{in}$ to produce $V_i^{out}$ using set of operations that varies by layer.\n",
    "\n",
    "With this new notation, we can redfine $M$ in terms of its layers:\n",
    "$$\\begin{align*}\n",
    "  M(img) & =L_4(L_3(L_2(L_1(img)))) \\\\\n",
    "  & =pred.\n",
    "\\end{align*}$$\n",
    "Thus, a model's prediction is simply the output of its cascaded layer functions.\n",
    "\n",
    "Let's now take a look at each of the layers and how we can rederive their functions to be built on the FPGA.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- container: dark -->\n",
    "#### Layer 1: Conv2D\n",
    "The 2D convolutional layer has weights $W^1$ and biases $B^1$ that are defined by \n",
    "$$\\begin{align*}\n",
    "    & W^1:[x=2,y=2,z=8]=\n",
    "    \\begin{bmatrix}\n",
    "        \\begin{bmatrix}\n",
    "            \\begin{bmatrix} o_1 & \\dots & o_k & \\dots & o_z \\end{bmatrix}_{1,1} \\\\\n",
    "            \\vdots \\\\\n",
    "            \\begin{bmatrix} p_1 & \\dots & p_k & \\dots & p_z \\end{bmatrix}_{1,y}\n",
    "        \\end{bmatrix}_1 \\\\\n",
    "        \\vdots \\\\\n",
    "        \\begin{bmatrix}\n",
    "            \\begin{bmatrix} q_1 & \\dots & q_k & \\dots & q_z \\end{bmatrix}_{x, 1} \\\\\n",
    "            \\vdots \\\\\n",
    "            \\begin{bmatrix} r_1 & \\dots & r_k & \\dots & r_z \\end{bmatrix}_{x, y}\n",
    "        \\end{bmatrix}_x\n",
    "    \\end{bmatrix}, \\\\\n",
    "    & B^1:[z=8]=\\begin{bmatrix} b_1 & \\dots & b_z \\end{bmatrix}\n",
    "\\end{align*}$$ \n",
    "for $k=1,\\dots,z$. And since this is the first layer, the input data is the image, or rather \n",
    "$$V^{in}_1:[n=28,n]=img,$$\n",
    "and the output data is defined by $V^{out}_1:[n-1,n-1,z]$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Mathematical Description\n",
    "So, how does the convolutional layer produce its output? We start by taking two counters $0\\leq i,j\\leq n-1$ and assigning an array `sub` to a 2D subset of $V_1^{in}$. Specifically, we take the $j$ through $j+y$ elements in the $i$ through $i+x$ rows of $V_1^{in}$. We can rigidly define `sub` as \n",
    "$$sub:[x, y]=V^{in}_{1_{i:i+x,~j:j+y}}=\n",
    "\\begin{bmatrix}\n",
    "    \\begin{bmatrix} \n",
    "        f_1 & \\dots & f_y\n",
    "    \\end{bmatrix}_1 \\\\\n",
    "    \\vdots \\\\\n",
    "    \\begin{bmatrix}\n",
    "        g_1 & \\dots & g_y\n",
    "    \\end{bmatrix}_x\n",
    "\\end{bmatrix}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then take the dot product of `sub` and $W^1$ with respect to the second and third dimensions which yields \n",
    "$$\n",
    "conv_{i,j}:[z]=\n",
    "\\begin{bmatrix}\n",
    "    f_1\\cdot o_1+\\dots+f_y\\cdot p_1+g_1\\cdot q_1+\\dots+g_y\\cdot r_1 \\\\\n",
    "    \\vdots \\\\\n",
    "    f_1\\cdot o_k+\\dots+f_y\\cdot p_k+g_1\\cdot q_k+\\dots+g_y\\cdot r_k \\\\\n",
    "    \\vdots \\\\\n",
    "    f_1\\cdot o_z+\\dots f_y\\cdot p_z+g_1\\cdot q_z+\\dots+g_y\\cdot r_z\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "for $k=1,\\dots,z$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we add the $z$ biases in $B^1$ to the `z` elements in $conv_{i,j}$ and store the resulting vector in the $i$-th row and $j$-th column of the output array:\n",
    "$$\n",
    "V_{1_{i,j}}^{out}=\n",
    "\\begin{bmatrix} \n",
    "    conv_{i,j,1}+b_1 \\\\\n",
    "    \\vdots \\\\\n",
    "    conv_{i,j,k}+b_k \\\\\n",
    "    \\vdots \\\\\n",
    "    conv_{i,j,z}+b_z\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "for $k=1,\\dots,z$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Programatic Description\n",
    "Before we think about the functionality in terms of hardware, we introduce a code block of Python mixed with pseudocode to put the math in context (which I promise is far more readable than the Verilog implementation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python\n",
    "import numpy as np\n",
    "\n",
    "def Conv2D(\n",
    "    V1in: np.ndarray[28, 28], \n",
    "    W1: np.ndarray[2, 2, 8], \n",
    "    B1: np.ndarray[8]\n",
    "):  \n",
    "    n, n = V1in.shape\n",
    "    x, y, z = W1.shape\n",
    "\n",
    "    # init the output array\n",
    "    V1out = np.ndarray[n - 1,  n - 1, z]  # (27, 27, 8)\n",
    "\n",
    "    for i in range(n - 1):  # rows if image\n",
    "        for j in range(n - 1):  # columns of image\n",
    "            # array of shape `(x, y)`\n",
    "            sub: np.ndarray[x, y] = V1in[i:i + x, j:j + y] \n",
    "\n",
    "            # vector of length `z`\n",
    "            convij: np.ndarray[z] = np.sum(sub * W1, axis=(0, 1))\n",
    "\n",
    "            V1out[i, j] = convij + B1\n",
    "\n",
    "    return V1out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Verython Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python\n",
    "class Conv2D(Layer):\n",
    "    \"\"\"\n",
    "    img of size (n, n)\n",
    "    kernel of size (x, y, z)\n",
    "\n",
    "    We have z=8 filters, each of which are x=2 by y=2\n",
    "    Let FIL_1 denote the first filter(i, j) using the notation above, then:\n",
    "    kernel = [ [f1      [h1\n",
    "                f2       h2\n",
    "                g1 ,     j1 ...\n",
    "                g2]      j2]       ]\n",
    "\n",
    "           = [FIL_1.T, FIL_2.T, ... , FIL_8.T]  --> this is hard to think about\n",
    "                                            since these filters are transposed\n",
    "\n",
    "    at each iteration i=1,..., n - 1 and j=1,..., n - 1:\n",
    "    sub(i, j) of size (x, y) is subset of the image\n",
    "    sub(i, j) = [[f1, ..., fx],\n",
    "                 [g1, ..., gy]]\n",
    "\n",
    "    kernel = [[ F1 = [o1, ..., oz],\n",
    "                ...\n",
    "                Fx = [p1, ..., pz]],\n",
    "              [ G1 = [q1, ..., qz],\n",
    "                ...\n",
    "                Gy = [r1, ..., rz]]\n",
    "\n",
    "    prod(i, j) = sub(i, j) * kernel\n",
    "               = [[ f1 * F1,\n",
    "                    ...\n",
    "                    fx * Fx],\n",
    "                  [ g1 * G1,\n",
    "                    gy * Gy]]\n",
    "    sum(i, j) = prod.sum(axis=(0, 1)) =\n",
    "        [\n",
    "            f1 * o1 + ... + fx * p1 + g1 * q1 + ... + gy * r1,\n",
    "            ...\n",
    "            f1 * oz + ... + fx * pz + g1 * qz + ... + gy * rz\n",
    "        ]\n",
    "\n",
    "    output is array of size (n - 1, n - 1, z) where\n",
    "    output[i, j] = sum(i, j)\n",
    "    ------------\n",
    "    This very abstract representation makes hard to develop the intuition,\n",
    "    let's ignore this for now\n",
    "    ------------\n",
    "    mat is a 2x2 slice of the image --> img[i:i+2, j:j+2]\n",
    "    Let's say:\n",
    "    mat = np.array([[[0.1],\n",
    "                     [0.5]],\n",
    "                     [[1.],\n",
    "                     [1.]]])\n",
    "    kernel = np.ones( (2,2,8) )\n",
    "\n",
    "    prod(i, j) = mat * kernel\n",
    "               = np.array([[[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
    "                            [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]],\n",
    "                            [[1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. ],\n",
    "                            [1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. ]]])\n",
    "    output(i, j) = np.array([2.6, 2.6, 2.6, 2.6, 2.6, 2.6, 2.6, 2.6])\n",
    "                                             --> we sum the columns\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        int_width: BitWidth,\n",
    "        dec_width: BitWidth,\n",
    "        weights_np: np.ndarray,\n",
    "        biases_np: np.ndarray,\n",
    "        input_mem: M10K,\n",
    "        output_mem: M10K,\n",
    "        input_shape: Optional[InputShape],\n",
    "        output_shape: Optional[OutputShape]\n",
    "    ):\n",
    "\n",
    "        # create the signed mult and sigmoid modules\n",
    "        self.signed_mult = SignedMult(int_width, dec_width)\n",
    "\n",
    "        super().__init__(\n",
    "            int_width=int_width,\n",
    "            dec_width=dec_width,\n",
    "            weights_np=weights_np,\n",
    "            biases_np=biases_np,\n",
    "            input_mem=input_mem,\n",
    "            output_mem=output_mem,\n",
    "            input_shape=input_shape,\n",
    "            output_shape=output_shape,\n",
    "            objects=[self.signed_mult]\n",
    "        )\n",
    "\n",
    "        # make sure input data is signed\n",
    "        self.inp_data.signed = True\n",
    "\n",
    "        # make output data a wire\n",
    "        self.out_data.dtype = V_Wire\n",
    "\n",
    "        x, y, z = weights_np.shape\n",
    "\n",
    "        assert x == y, weights_np\n",
    "\n",
    "        # the constant used to scale the inputs (>> 8 -> / 256)\n",
    "        self.input_scaler = 8\n",
    "\n",
    "        # store the target size (** MIGHT BE SOURCE OF ERROR)\n",
    "        self.target_size = int(np.sqrt(self.input_mem.size)) - 1\n",
    "        print(f\"{nameof(self)} Target Size: {self.target_size}\")\n",
    "\n",
    "        # the number of rows in the flattened weights\n",
    "        self.w_rows = x * x\n",
    "\n",
    "        # create registers used as iteration indices\n",
    "        # ti=0, ..., target_size - 1\n",
    "        self.ti = self.var(dtype=V_Reg,\n",
    "                           width=self.input_mem.addr_width,\n",
    "                           name=\"ti\")\n",
    "\n",
    "        # tj=0, ..., target_size - 1\n",
    "        self.tj = self.var(dtype=V_Reg,\n",
    "                           width=self.input_mem.addr_width,\n",
    "                           name=\"tj\")\n",
    "\n",
    "        # ii=0, ..., x - 1\n",
    "        self.ii = self.var(dtype=V_Reg,\n",
    "                           width=self.input_mem.addr_width,\n",
    "                           name=\"ii\")\n",
    "\n",
    "        # jj=0, ..., x - 1\n",
    "        self.jj = self.var(dtype=V_Reg,\n",
    "                           width=self.input_mem.addr_width,\n",
    "                           name=\"jj\")\n",
    "\n",
    "        # r=0, ..., x * x - 1\n",
    "        self.r = self.var(dtype=V_Reg,\n",
    "                          width=self.input_mem.addr_width,\n",
    "                          name=\"r\")\n",
    "\n",
    "        # wc=0, ..., z - 1\n",
    "        self.wc = self.var(dtype=V_Reg,\n",
    "                           width=self.w_addr.width,\n",
    "                           name=\"wc\")\n",
    "\n",
    "        # create a register array for the sub image\n",
    "        self.sub = self.var(\n",
    "            dtype=V_RegArray,\n",
    "            width=self.width,\n",
    "            size=x * x,\n",
    "            signed=True,\n",
    "            name=\"sub_img\"\n",
    "        )\n",
    "\n",
    "        # create a wire to to hold the output of the convolution\n",
    "        self.conv_out = self.var(\n",
    "            dtype=V_Wire,\n",
    "            width=self.width,\n",
    "            size=self.output_mem.size,\n",
    "            signed=True,\n",
    "            name=\"conv_out\"\n",
    "        )\n",
    "\n",
    "        # create `self.w_rows` multiplier outputs\n",
    "        self.mult_outs = [self.var(dtype=V_Wire,\n",
    "                                   width=self.signed_mult.width,\n",
    "                                   signed=True,\n",
    "                                   name=f\"mult_out_{wr}\")\n",
    "                          for wr in range(self.w_rows)]\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(\n",
    "        x: np.ndarray,\n",
    "        weights_np: Weights,\n",
    "        biases_np: Biases\n",
    "    ):\n",
    "\n",
    "        Z1 = convolve_flat(x, weights_np)\n",
    "\n",
    "        return Z1 + biases_np\n",
    "\n",
    "    def convert_model_params(\n",
    "        self,\n",
    "        int_width: BitWidth,\n",
    "        dec_width: BitWidth,\n",
    "        weights_np: np.ndarray,\n",
    "        biases_np: np.ndarray\n",
    "    ) -> Tuple[V_Array, V_Array]:\n",
    "\n",
    "        assert biases_np.ndim == 1, biases_np\n",
    "\n",
    "        w_flat = weights_np.flatten()\n",
    "\n",
    "        weights = V_Array(\n",
    "            module=self,\n",
    "            dtype=V_ParameterArray,\n",
    "            width=int_width + dec_width,\n",
    "            size=len(w_flat),\n",
    "            signed=True,\n",
    "            data=[V_FixedPoint(v, int_width, dec_width) for v in w_flat],\n",
    "            name=f\"conv2d_weights\"\n",
    "        )\n",
    "\n",
    "        biases = V_Array(\n",
    "            module=self,\n",
    "            dtype=V_ParameterArray,\n",
    "            width=int_width + dec_width,\n",
    "            size=len(biases_np),\n",
    "            signed=True,\n",
    "            data=[V_FixedPoint(v, int_width, dec_width)\n",
    "                  for v in biases_np],\n",
    "            name=f\"conv2d_biases\"\n",
    "        )\n",
    "\n",
    "        return weights, biases\n",
    "\n",
    "    def generate(self) -> V_Block:\n",
    "        x, y, z = self.weights_np.shape\n",
    "\n",
    "        vsm = V_StateMachine(_StReset, _StWaitValid,\n",
    "                             _StResetSub, _StSetInpAddr, _StSubBuffer,\n",
    "                             _StSetSub, _StComputeConv, _StIncWeightIndices,\n",
    "                             _StIncTargetIndices)\n",
    "\n",
    "        # instantiate x * x signed mult modules\n",
    "        mult = self.signed_mult\n",
    "        self.signed_mult_inss = [self.signed_mult.instantiate(\n",
    "            self,\n",
    "            (V_Empty(), mult.clk),\n",
    "            (V_Empty(), mult.reset),\n",
    "            (V_Empty(), mult.valid),\n",
    "            (V_Empty(), mult.done),\n",
    "            (V_Empty(), mult.ready),\n",
    "            (self.sub[wr], mult.input_ports[0]),\n",
    "            (self.weights[self.wc + wr * z], mult.input_ports[1]),\n",
    "            (self.mult_outs[wr], mult.output_ports[0])\n",
    "        ) for wr in range(self.w_rows)]\n",
    "\n",
    "        return super().generate(vsm, V_Block(\n",
    "            \"// instantiate the multipliers\",\n",
    "            *[line for mult_ins in self.signed_mult_inss for line in mult_ins],\n",
    "\n",
    "            \"\\n// assign the output of the convolution\",\n",
    "            self.out_data.set(\n",
    "                V_Sum(*self.mult_outs, self.biases[self.wc]))\n",
    "            # self.conv_out.set(\n",
    "            #     V_Sum(*self.mult_outs, self.biases[self.out_addr]))\n",
    "        ))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Conv2D State Machine:\n",
    "img of size (n, n)\n",
    "kernel of size (x, y, z)\n",
    "\n",
    "\n",
    "first load each input into a local register array\n",
    "reasoning:\n",
    "    at each iteration, we need to get 4 new inputs from input memory. this\n",
    "    would take at least 5 cycles to set input addr and get new data\n",
    "\n",
    "    getting all the inputs into a reg array would allow us to get new values\n",
    "    in same cycle\n",
    "\n",
    "call this reg array `inp_reg`\n",
    "for iteration i=1,..., n - 1 and j=1,..., n - 1:\n",
    "filter(i, j) is of size (x, y)\n",
    "\n",
    "\n",
    "set the sub by \n",
    "for ti in range(target_size):\n",
    "    for tj in range(target_size):\n",
    "        sub[0:x * x - 1] = inp_reg[ti:ti + x, ti:ti + x]\n",
    "\n",
    "\n",
    "go straight to computing this the prod.sum:\n",
    "sum(i, j) = prod.sum(axis=(0, 1)) =\n",
    "        [\n",
    "            f1 * o1 + ... + fx * p1 + g1 * q1 + ... + gy * r1,\n",
    "            ...\n",
    "            f1 * oz + ... + fx * pz + g1 * qz + ... + gy * rz\n",
    "        ]\n",
    "        =\n",
    "        [\n",
    "            sub[0] * W[0 + 0 * z] + ... + sub[wr] * W[0 + wr * z],\n",
    "            sub[0] * W[1 + 0 * z] + ... + sub[wr] * W[1 + wr * z],\n",
    "            ...\n",
    "            sub[0] * W[wc + 0 * z] + ... + sub[wr] * W[wc + wr * z]\n",
    "        ]\n",
    "where wr=0, ..., x * x - 1 and is the row index and \n",
    "      wc=0, ...., z - 1\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class _StReset(V_State):\n",
    "    \"\"\"\n",
    "    init input read addr\n",
    "    init output write addr\n",
    "    lower output write enable\n",
    "\n",
    "    init iteration variables\n",
    "\n",
    "    raise sig reset\n",
    "    lower sig valid\n",
    "\n",
    "    go to StWaitValid\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Conv2D) -> V_Block:\n",
    "\n",
    "        return V_Block(\n",
    "            m.inp_addr.set(m.input_mem.base_addr),\n",
    "            m.out_addr.set(m.output_mem.base_addr),\n",
    "            m.out_we.set(V_Low),\n",
    "\n",
    "            m.ti.set(V_Low),\n",
    "            m.tj.set(V_Low),\n",
    "            m.wc.set(V_Low),\n",
    "\n",
    "            _StWaitValid\n",
    "        )\n",
    "\n",
    "\n",
    "class _StWaitValid(V_State):\n",
    "    \"\"\"\n",
    "    if (valid)\n",
    "        go to StInitInputReg\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Conv2D) -> V_Block:\n",
    "\n",
    "        return V_Block(\n",
    "            *V_If(m.valid)(\n",
    "\n",
    "                _StResetSub\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "class _StResetSub(V_State):\n",
    "    \"\"\"\n",
    "    reset the counters used for sub\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Conv2D) -> V_Block:\n",
    "        return V_Block(\n",
    "            m.ii.set(V_Low),\n",
    "            m.jj.set(V_Low),\n",
    "            m.r.set(V_Low),\n",
    "\n",
    "            _StSetInpAddr\n",
    "        )\n",
    "\n",
    "\n",
    "class _StSetInpAddr(V_State):\n",
    "    \"\"\"\n",
    "    set the input address\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Conv2D) -> V_Block:\n",
    "        n = m.target_size + 1\n",
    "\n",
    "        return V_Block(\n",
    "            m.inp_addr.set((V_Par(m.ti + m.ii) * n) + m.tj + m.jj),\n",
    "\n",
    "            _StSubBuffer\n",
    "        )\n",
    "\n",
    "\n",
    "class _StSubBuffer(V_State):\n",
    "    \"\"\"\n",
    "    delay 1 cycle\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Conv2D) -> V_Block:\n",
    "        return V_Block(\n",
    "\n",
    "            _StSetSub\n",
    "        )\n",
    "\n",
    "\n",
    "class _StSetSub(V_State):\n",
    "    \"\"\"\n",
    "    set the sub by \n",
    "    for ti in range(target_size):\n",
    "        for tj in range(target_size):\n",
    "            sub[0:x * x - 1] = inp_reg[ti:ti + x, ti:ti + x]\n",
    "\n",
    "            set wc to zero\n",
    "\n",
    "            go to StComputeConv\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Conv2D) -> V_Block:\n",
    "        # should be the first dim of the input shape\n",
    "        x, *_ = m.weights_np.shape\n",
    "\n",
    "        # indices = [(ii * n, jj) for ii in range(k) for jj in range(k)]\n",
    "\n",
    "        max_ii = x - 1\n",
    "        max_jj = x - 1\n",
    "        max_r = x * x - 1\n",
    "\n",
    "        return V_Block(\n",
    "            m.sub[m.r].set(m.inp_data),\n",
    "\n",
    "            *V_If(m.r == max_r)(\n",
    "                m.wc.set(V_Low),\n",
    "                _StComputeConv\n",
    "            ), *V_Else(\n",
    "                m.r.set(m.r + 1),\n",
    "\n",
    "                # dont need to handle the case of max_ii because m.r == max_r\n",
    "                *V_If(m.jj == max_jj)(\n",
    "                    m.ii.set(m.ii + 1),\n",
    "                    m.jj.set(V_Low)\n",
    "                ), *V_Else(\n",
    "                    m.jj.set(m.jj + 1)\n",
    "                ),\n",
    "\n",
    "                _StSetInpAddr\n",
    "            )\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "class _StComputeConv(V_State):\n",
    "    \"\"\"\n",
    "    raise output write enable\n",
    "\n",
    "    go to StComputeSig\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Conv2D) -> V_Block:\n",
    "\n",
    "        return V_Block(\n",
    "            m.out_we.set(V_High),\n",
    "\n",
    "            _StIncWeightIndices\n",
    "        )\n",
    "\n",
    "\n",
    "class _StIncWeightIndices(V_State):\n",
    "    \"\"\"\n",
    "    clear the output write enable\n",
    "\n",
    "    if (wc == w_rows - 1)\n",
    "        set wc to 0\n",
    "\n",
    "        if (output addr = max output addr - 1)\n",
    "            go to StDone\n",
    "        else \n",
    "            inc the output addr \n",
    "\n",
    "            go to StIncTargetIndices\n",
    "    else\n",
    "        inc wc\n",
    "        inc the output addr\n",
    "\n",
    "        go to StComputeConv\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Conv2D) -> V_Block:\n",
    "        max_out_addr = m.output_mem.size - 1\n",
    "        # max_rows = m.w_rows - 1\n",
    "        x, y, z = m.weights_np.shape\n",
    "        max_cols = z - 1\n",
    "\n",
    "        return V_Block(\n",
    "            m.out_we.set(V_Low),\n",
    "\n",
    "            *V_If(m.wc == max_cols)(\n",
    "                m.wc.set(V_Low),\n",
    "\n",
    "                *V_If(m.out_addr == max_out_addr)(\n",
    "                    V_StDone\n",
    "                ), *V_Else(\n",
    "                    m.out_addr.set(m.out_addr + 1),\n",
    "\n",
    "                    _StIncTargetIndices\n",
    "                )\n",
    "            ), *V_Else(\n",
    "                m.wc.set(m.wc + 1),\n",
    "                m.out_addr.set(m.out_addr + 1),\n",
    "\n",
    "                _StComputeConv\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "class _StIncTargetIndices(V_State):\n",
    "    \"\"\"\n",
    "\n",
    "    if (m.tj == m.target_size - 1)\n",
    "        set m.tj to 0\n",
    "\n",
    "        if (m.ti == m.target_size - 1)\n",
    "            go to StDone\n",
    "        else\n",
    "            inc m.ti\n",
    "            go to StSetSub\n",
    "    else\n",
    "        inc m.tj\n",
    "\n",
    "        go to StSetSub\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Conv2D) -> V_Block:\n",
    "        max_iter = m.target_size - 1\n",
    "\n",
    "        return V_Block(\n",
    "            *V_If(m.tj == max_iter)(\n",
    "                m.tj.set(V_Low),\n",
    "\n",
    "                *V_If(m.ti == max_iter)(\n",
    "                    V_StDone\n",
    "                ), *V_Else(\n",
    "                    m.ti.set(m.ti + 1),\n",
    "                    _StResetSub\n",
    "                )\n",
    "            ), *V_Else(\n",
    "                m.tj.set(m.tj + 1),\n",
    "\n",
    "                _StResetSub\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated Verilog: [Layer1](https://github.com/jfw225/mnist-cnn-fpga/blob/main/deployment/DE1-SoC_Computer_15_640_current/verilog/layer1.sv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<!-- container: default -->\n",
    "#### Layer 2: Maxpool\n",
    "This maxpool layer has no weights or biases. Additionally, its input and output are defined by \n",
    "$$\\begin{align*}\n",
    "    & V_2^{in}: [x=27, y=27, n=8]=V_1^{out}, \\\\\n",
    "    & V_2^{out}:[\\lceil x/2\\rceil=13, \\lceil y/2\\rceil=13, n=8].\n",
    "\\end{align*}$$\n",
    "where $\\lceil r\\rceil$ is $r$ rounded up to the nearest integer for some $r\\in\\mathbb{R}$.\n",
    "We also use $s=2$ for the stride hyperparameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mathematical Description\n",
    "Like with the last layer, we start by taking two counters $0\\leq i\\leq x,0\\leq j\\leq y$ and assigning an array `window` to a 2D subset of $V_2^{in}$. Specifically, we take the $j$ through $j+s$ elements in the $i$ through $i+s$ rows of $V_2^{in}$. We can rigidly define `window` as \n",
    "$$window_{i,j}:[s, s, n]=V_{2_{i:i+s,j:j+s}}^{in}=\n",
    "\\begin{bmatrix}\n",
    "    \\begin{bmatrix}\n",
    "        \\begin{bmatrix}\n",
    "            o_1 & \\dots & o_k & \\dots & o_n\n",
    "        \\end{bmatrix}_{1,1} \\\\\n",
    "        \\vdots \\\\\n",
    "        \\begin{bmatrix}\n",
    "            p_1 & \\dots & p_k & \\dots & p_n\n",
    "        \\end{bmatrix}_{1,s}\n",
    "    \\end{bmatrix}_1 \\\\\n",
    "    \\vdots \\\\\n",
    "    \\begin{bmatrix}\n",
    "        \\begin{bmatrix}\n",
    "            q_1 & \\dots & q_k & \\dots & q_n \n",
    "        \\end{bmatrix}_{s,1} \\\\\n",
    "        \\vdots \\\\\n",
    "        \\begin{bmatrix}\n",
    "            r_1 & \\dots & r_k & \\dots & r_n\n",
    "        \\end{bmatrix}_{s,s}\n",
    "    \\end{bmatrix}_s\n",
    "\\end{bmatrix}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then take the column-wise maximum of `window` (i.e. the max of the elements aligned vertically in the array above) which yields\n",
    "$$\n",
    "max_{i,j}:[n]=\n",
    "\\begin{bmatrix}\n",
    "    \\max\\left\\{o_1,\\dots,p_1,q_1,\\dots,r_1\\right\\} \\\\\n",
    "    \\vdots \\\\\n",
    "    \\max\\left\\{o_k,\\dots,p_k,q_k,\\dots,r_k\\right\\} \\\\\n",
    "    \\vdots \\\\\n",
    "    \\max\\left\\{o_n,\\dots,p_n,q_n,\\dots,r_n\\right\\}\n",
    "\\end{bmatrix}$$\n",
    "for $k=1,\\dots,n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we take the length-$n$ vector $max_{i,j}$ and store it in the $\\lceil i/s\\rceil$-th row and the $\\lceil j/s\\rceil$-th column of the output array:\n",
    "$$V_{1_{\\lceil i/s\\rceil,\\lceil j/s\\rceil}}^{out}=max_{i,j}.$$\n",
    "After each iteration, we increment $j$ by $s$ and repeat this until $j+s>y$. At this point, we increment $i$ by $s$ and continue to iterate until $i+s>x$. When this is true, the pooling has completed. This stop condition will be come more clear in the *Programatic Description*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Programatic Description\n",
    "Like before, we introduce a code block of Python mixed with pseudocode to put the math in context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python\n",
    "import numpy as np\n",
    "\n",
    "def Maxpool(V2in: np.ndarray[27, 27, 8], s=2):\n",
    "    x, y, n = image.shape\n",
    "\n",
    "    V2out = np.ndarray[x // 2, y // 2, n]\n",
    "\n",
    "    # slide the window over every part of the image using stride s\n",
    "    # take the maximum value at each step\n",
    "    i = 0\n",
    "\n",
    "    # slide the max pooling window vertically across the image\n",
    "    while i + s <= x:\n",
    "        j = 0\n",
    "\n",
    "        # slide the max pooling window horizontally across the image\n",
    "        while j + s <= y:\n",
    "            # choose the max value in the window at each step\n",
    "            maxij = np.max(V2in[i:i + s, j:j + s], axis=(0, 1))\n",
    "\n",
    "            # store it to output matrix\n",
    "            V2out[i // s, j // s] = maxij\n",
    "            \n",
    "            # increment `j`\n",
    "            j += s\n",
    "\n",
    "        # increment `i`\n",
    "        i += s\n",
    "\n",
    "    return V2out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Verython Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python\n",
    "class Maxpool(Layer):\n",
    "    \"\"\"\n",
    "    Let the input to this layer be\n",
    "\n",
    "    mp_input of size (y, x, n)\n",
    "    window is of size (f * f * n)\n",
    "\n",
    "    window = [[\n",
    "        A1 = [o1, ..., on],\n",
    "        ...,\n",
    "        Af = [p1, ..., pn]\n",
    "    ], [\n",
    "        B1 = [q1, ..., qn],\n",
    "        ...,\n",
    "        Bf = [r1, ..., rn]\n",
    "    ]]\n",
    "\n",
    "    the output at iteration (i, j) is the columnwise max of\n",
    "    [A1, ..., Af, B1, ..., Bf], or rather,\n",
    "    max(i, j) of size (n) = [\n",
    "        max(o1, ..., p1, q1, ..., r1),\n",
    "        ...,\n",
    "        max(on, ..., pn, qn, ..., rn)\n",
    "    ] = [\n",
    "        max(\n",
    "            window[0 + 0 * z * z]\n",
    "            + ... + window[0 + wr * z * z] + ... +\n",
    "            window[0 + (z * z - 1) * z * z]\n",
    "        ), ...,\n",
    "        max(\n",
    "            window[wc + 0 * z * z]\n",
    "            + ... + window[wc + wr * z * z] + ... +\n",
    "            window[wc + (z * z - 1) * z * z]\n",
    "        ), ...,\n",
    "        max(\n",
    "            window[(n - 1) + 0 * z * z]\n",
    "            + ... + window[(n - 1) + wr * z * z] + ... +\n",
    "            window[(n - 1) + (z * z - 1) * z * z]\n",
    "        )\n",
    "        max(window[wc + wr * z * z])\n",
    "    ]\n",
    "\n",
    "    where wc=0, ..., n - 1 is the column sweep and\n",
    "    wr=0, ..., z * z - 1 is the row sweep.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        int_width: BitWidth,\n",
    "        dec_width: BitWidth,\n",
    "        weights_np: np.ndarray,\n",
    "        biases_np: np.ndarray,\n",
    "        input_mem: M10K,\n",
    "        output_mem: M10K,\n",
    "        input_shape: Optional[InputShape],\n",
    "        output_shape: Optional[OutputShape]\n",
    "    ):\n",
    "\n",
    "        # create the max. mult, exponential, and div modules\n",
    "        self.signed_max = SignedMax(int_width, dec_width)\n",
    "\n",
    "        super().__init__(\n",
    "            int_width=int_width,\n",
    "            dec_width=dec_width,\n",
    "            weights_np=weights_np,\n",
    "            biases_np=biases_np,\n",
    "            input_mem=input_mem,\n",
    "            output_mem=output_mem,\n",
    "            input_shape=input_shape,\n",
    "            output_shape=output_shape,\n",
    "            objects=[self.signed_max]\n",
    "        )\n",
    "\n",
    "        # configure the output data as a wire\n",
    "        self.out_data.dtype = V_Reg\n",
    "\n",
    "        # store f and stride values\n",
    "        self._f = 2\n",
    "        self._s = 2\n",
    "\n",
    "        # we assume the f is even for now\n",
    "        assert self._f % 2 == 0, self._f\n",
    "\n",
    "        # create a register array for the sliding window\n",
    "        self.window = self.var(dtype=V_RegArray,\n",
    "                               width=self.width,\n",
    "                               size=self.f * self.f * self.n,\n",
    "                               signed=True,\n",
    "                               name=\"window\")\n",
    "\n",
    "        # create iteration variables as in `maxpool_flat`\n",
    "        self.curr_y = self.var(dtype=V_Reg,\n",
    "                               width=self.input_mem.addr_width,\n",
    "                               name=\"curr_y\")\n",
    "        self.out_y = self.var(dtype=V_Reg,\n",
    "                              width=self.output_mem.addr_width,\n",
    "                              name=\"out_y\")\n",
    "\n",
    "        self.curr_x = self.var(dtype=V_Reg,\n",
    "                               width=self.input_mem.addr_width,\n",
    "                               name=\"curr_x\")\n",
    "        self.out_x = self.var(dtype=V_Reg,\n",
    "                              width=self.output_mem.addr_width,\n",
    "                              name=\"out_x\")\n",
    "\n",
    "        # jj=0, ..., f - 1\n",
    "        self.jj = self.var(dtype=V_Reg,\n",
    "                           width=self.input_mem.addr_width,\n",
    "                           name=\"jj\")\n",
    "\n",
    "        # ii=0, ..., f - 1\n",
    "        self.ii = self.var(dtype=V_Reg,\n",
    "                           width=self.input_mem.addr_width,\n",
    "                           name=\"ii\")\n",
    "\n",
    "        # kk=0, ..., n - 1\n",
    "        self.kk = self.var(dtype=V_Reg,\n",
    "                           width=self.input_mem.addr_width,\n",
    "                           name=\"kk\")\n",
    "\n",
    "        # ww=0, ..., f * f * n - 1\n",
    "        self.ww = self.var(dtype=V_Reg,\n",
    "                           width=ceil(log2(self.window.size)),\n",
    "                           name=\"ww\")\n",
    "\n",
    "        # wc=0, ..., n - 1\n",
    "        self.wc = self.var(dtype=V_Reg,\n",
    "                           width=self.output_mem.addr_width,\n",
    "                           name=\"wc\")\n",
    "\n",
    "        # wr=0, ..., f * f - 1\n",
    "        self.wr = self.var(dtype=V_Reg,\n",
    "                           width=ceil(log2(self.window.size)),\n",
    "                           name=\"wr\")\n",
    "\n",
    "        # holds the output of the signed max module\n",
    "        self.max_out = self.var(dtype=V_Wire,\n",
    "                                width=self.width,\n",
    "                                signed=True,\n",
    "                                name=\"max_out\")\n",
    "\n",
    "    @property\n",
    "    def f(self):\n",
    "        \"\"\"\n",
    "        The `f` parameter in `maxpool_flat`.\n",
    "        TODO: KEN COME BACK AND EXPLAIN THIS\n",
    "        \"\"\"\n",
    "\n",
    "        return self._f\n",
    "\n",
    "    @property\n",
    "    def s(self):\n",
    "        \"\"\"\n",
    "        The stride parameter in `maxpool_flat`.\n",
    "        \"\"\"\n",
    "\n",
    "        return self._s\n",
    "\n",
    "    @property\n",
    "    def y(self):\n",
    "        \"\"\"\n",
    "        Input array is of size `(y, x, n)`.\n",
    "        \"\"\"\n",
    "\n",
    "        y, x, n = self.input_shape\n",
    "\n",
    "        return y\n",
    "\n",
    "    @property\n",
    "    def x(self):\n",
    "        \"\"\"\n",
    "        Input array is of size `(y, x, n)`.\n",
    "        \"\"\"\n",
    "\n",
    "        y, x, n = self.input_shape\n",
    "\n",
    "        return x\n",
    "\n",
    "    @property\n",
    "    def n(self):\n",
    "        \"\"\"\n",
    "        Input array is of size `(y, x, n)`.\n",
    "        \"\"\"\n",
    "\n",
    "        y, x, n = self.input_shape\n",
    "\n",
    "        return n\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(\n",
    "        x: np.ndarray,\n",
    "        weights_np: Weights,\n",
    "        biases_np: Biases\n",
    "    ):\n",
    "\n",
    "        return maxpool_flat(x)\n",
    "\n",
    "    def convert_model_params(\n",
    "        self,\n",
    "        int_width: BitWidth,\n",
    "        dec_width: BitWidth,\n",
    "        weights_np: np.ndarray,\n",
    "        biases_np: np.ndarray\n",
    "    ) -> Tuple[V_Array, V_Array]:\n",
    "\n",
    "        return None, None\n",
    "\n",
    "    def generate(self) -> V_Block:\n",
    "\n",
    "        vsm = V_StateMachine(_StReset, _StWaitValid,\n",
    "                             _StResetWindow, _StSetInpAddr,\n",
    "                             _StWindowBuffer, _StSetWindow,\n",
    "                             _StMaxReset, _StGetMaxOverWindow,\n",
    "                             _StFindMax, _StMaxBuffer,\n",
    "                             _StIncMaxpool, _StWriteData)\n",
    "\n",
    "        sm = self.signed_max\n",
    "\n",
    "        return super().generate(vsm, V_Block(\n",
    "            \"// instantiate the signed maximum module\",\n",
    "            *self.signed_max.instantiate(\n",
    "                self,\n",
    "                (V_Empty(), sm.clk),\n",
    "                (V_Empty(), sm.reset),\n",
    "                (V_Empty(), sm.valid),\n",
    "                (V_Empty(), sm.done),\n",
    "                (V_Empty(), sm.ready),\n",
    "                (self.window[self.wc], sm.input_ports[0]),\n",
    "                (self.window[self.wc + self.wr * self.n], sm.input_ports[1]),\n",
    "                (self.max_out, sm.output_ports[0])\n",
    "            )\n",
    "        ))\n",
    "\n",
    "\n",
    "class _StReset(V_State):\n",
    "    \"\"\"\n",
    "    init input read addr\n",
    "    init output write addr\n",
    "    lower output write enable\n",
    "\n",
    "    init iteration variables\n",
    "\n",
    "    go to _StWaitValid\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Maxpool) -> V_Block:\n",
    "\n",
    "        return V_Block(\n",
    "            m.inp_addr.set(m.input_mem.base_addr),\n",
    "            m.out_addr.set(m.output_mem.base_addr),\n",
    "            m.out_we.set(V_Low),\n",
    "\n",
    "            m.curr_y.set(V_Low),\n",
    "            m.out_y.set(V_Low),\n",
    "            m.curr_x.set(V_Low),\n",
    "            m.out_x.set(V_Low),\n",
    "\n",
    "\n",
    "            _StWaitValid\n",
    "        )\n",
    "\n",
    "\n",
    "class _StWaitValid(V_State):\n",
    "    \"\"\"\n",
    "    if (valid)\n",
    "        go to StInitInputReg\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Maxpool) -> V_Block:\n",
    "\n",
    "        return V_Block(\n",
    "            *V_If(m.valid)(\n",
    "\n",
    "                _StResetWindow\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "class _StResetWindow(V_State):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Maxpool) -> V_Block:\n",
    "        return V_Block(\n",
    "            m.jj.set(V_Low),\n",
    "            m.ii.set(V_Low),\n",
    "            m.kk.set(V_Low),\n",
    "            m.ww.set(V_Low),\n",
    "\n",
    "            _StSetInpAddr\n",
    "        )\n",
    "\n",
    "\n",
    "class _StSetInpAddr(V_State):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Maxpool) -> V_Block:\n",
    "\n",
    "        return V_Block(\n",
    "            m.inp_addr.set(\n",
    "                (V_Par(m.curr_y + m.jj) * m.x * m.n) +\n",
    "                (V_Par(m.curr_x + m.ii) * m.n) +\n",
    "                m.kk),\n",
    "\n",
    "            _StWindowBuffer\n",
    "        )\n",
    "\n",
    "\n",
    "class _StWindowBuffer(V_State):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Maxpool) -> V_Block:\n",
    "\n",
    "        return V_Block(\n",
    "\n",
    "            _StSetWindow\n",
    "        )\n",
    "\n",
    "\n",
    "class _StSetWindow(V_State):\n",
    "    \"\"\"\n",
    "    set window = inp_reg[curr_y:curr_y + f, curr_x:curr_x + f]\n",
    "\n",
    "    inp_reg of size(y, x, n)\n",
    "    inp_reg[j, i, k] = inp_reg[(j * x * n) + (i * n) + k]\n",
    "\n",
    "    need to sweep\n",
    "    j=curr_y, ..., curr_y + f\n",
    "    i=curr_x, ..., curr_x + f\n",
    "    k=0, ..., n\n",
    "\n",
    "    go to _StFindMax\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Maxpool) -> V_Block:\n",
    "        max_jj = m.f - 1\n",
    "        max_ii = m.f - 1\n",
    "        max_kk = m.n - 1\n",
    "        max_ww = m.f * m.f * m.n - 1\n",
    "\n",
    "        return V_Block(\n",
    "            m.window[m.ww].set(m.inp_data),\n",
    "\n",
    "            *V_If(m.ww == max_ww)(\n",
    "\n",
    "                _StMaxReset\n",
    "            ), *V_Else(\n",
    "                m.ww.set(m.ww + 1),\n",
    "\n",
    "                *V_If(m.kk == max_kk)(\n",
    "                    m.kk.set(V_Low),\n",
    "\n",
    "                    # dont need to set jj low because that is case\n",
    "                    # where m.ww == max_ww\n",
    "                    *V_If(m.ii == max_ii)(\n",
    "                        m.ii.set(V_Low),\n",
    "                        m.jj.set(m.jj + 1)\n",
    "                    ), *V_Else(\n",
    "                        m.ii.set(m.ii + 1)\n",
    "                    )\n",
    "                ), *V_Else(\n",
    "                    m.kk.set(m.kk + 1)\n",
    "                ),\n",
    "\n",
    "                _StSetInpAddr\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "class _StMaxReset(V_State):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Maxpool) -> V_Block:\n",
    "\n",
    "        return V_Block(\n",
    "            m.wc.set(V_Low),\n",
    "            m.wr.set(V_High),\n",
    "\n",
    "            _StGetMaxOverWindow\n",
    "        )\n",
    "\n",
    "\n",
    "class _StGetMaxOverWindow(V_State):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Maxpool) -> V_Block:\n",
    "        max_wr = m.f * m.f - 1\n",
    "\n",
    "        return V_Block(\n",
    "            m.window[m.wc].set(m.max_out),\n",
    "\n",
    "            *V_If(m.wr == max_wr)(\n",
    "\n",
    "                _StFindMax\n",
    "            ), *V_Else(\n",
    "                m.wr.set(m.wr + 1),\n",
    "\n",
    "                _StGetMaxOverWindow\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "class _StFindMax(V_State):\n",
    "    \"\"\"\n",
    "    assign each of the column-wise maximums to the mp_out register\n",
    "\n",
    "    mp_out of size (y // 2, x // 2, n)\n",
    "\n",
    "    mp_out[(out_y * x // 2 * n) + (out_x * n) + wc] = max_outputs[wc]\n",
    "    for window column index wc=0,..., n - 1.\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Maxpool) -> V_Block:\n",
    "\n",
    "        return V_Block(\n",
    "            m.out_we.set(V_Low),\n",
    "            m.out_addr.set(\n",
    "                (m.out_y * (m.x // 2) * m.n) +\n",
    "                (m.out_x * m.n) +\n",
    "                m.wc\n",
    "            ),\n",
    "            # m.out_data.set(m.max_out_arr[m.wc]),\n",
    "            m.out_data.set(m.max_out),\n",
    "\n",
    "            _StMaxBuffer\n",
    "        )\n",
    "\n",
    "\n",
    "class _StMaxBuffer(V_State):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Maxpool) -> V_Block:\n",
    "        max_wc = m.n - 1\n",
    "\n",
    "        return V_Block(\n",
    "            m.out_we.set(V_High),\n",
    "\n",
    "            *V_If(m.wc == max_wc)(\n",
    "                _StIncMaxpool\n",
    "            ), *V_Else(\n",
    "                m.wc.set(m.wc + 1),\n",
    "                m.wr.set(1),\n",
    "\n",
    "                _StGetMaxOverWindow\n",
    "            )\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "class _StIncMaxpool(V_State):\n",
    "    \"\"\"\n",
    "    set each of the previously set mp_outs to to themselves\n",
    "\n",
    "    if (curr_x <= x - s - f)\n",
    "        set curr_x to 0\n",
    "        set out_x to 0\n",
    "\n",
    "        if (curr_y <= y - s - f)\n",
    "            set the output write enable\n",
    "\n",
    "            go to _StDotProduct\n",
    "        else\n",
    "            inc curr_y by s\n",
    "            inc out_y by 1\n",
    "\n",
    "            go to _StResetWindow\n",
    "\n",
    "    else\n",
    "        inc curr_x by s\n",
    "        inc out_x\n",
    "\n",
    "        go to _StResetWindow\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Maxpool) -> V_Block:\n",
    "        max_y = m.y - m.s - m.f\n",
    "        max_x = m.x - m.s - m.f\n",
    "\n",
    "        print(max_y, max_x)\n",
    "\n",
    "        return V_Block(\n",
    "            m.out_we.set(V_Low),\n",
    "\n",
    "            *V_If(m.curr_x > max_x)(\n",
    "                m.curr_x.set(V_Low),\n",
    "                m.out_x.set(V_Low),\n",
    "\n",
    "                *V_If(m.curr_y > max_y)(\n",
    "                    # m.out_we.set(V_High),\n",
    "                    V_StDone\n",
    "\n",
    "                    # _StWriteData,\n",
    "                ), *V_Else(\n",
    "                    m.curr_y.set(m.curr_y + m.s),\n",
    "                    m.out_y.set(m.out_y + 1),\n",
    "\n",
    "                    _StResetWindow\n",
    "                )\n",
    "            ), *V_Else(\n",
    "                m.curr_x.set(m.curr_x + m.s),\n",
    "                m.out_x.set(m.out_x + 1),\n",
    "\n",
    "                _StResetWindow\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "class _StWriteData(V_State):\n",
    "    \"\"\"\n",
    "    if (output addr == max)\n",
    "        clear output write enable\n",
    "\n",
    "        go to StDone\n",
    "    else\n",
    "        inc output addr\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Maxpool) -> V_Block:\n",
    "        max_out_addr = m.output_mem.size - 1\n",
    "\n",
    "        return V_Block(\n",
    "\n",
    "            *V_If(m.out_addr == max_out_addr)(\n",
    "                m.out_we.set(V_Low),\n",
    "\n",
    "                V_StDone\n",
    "            ), *V_Else(\n",
    "                m.out_addr.set(m.out_addr + 1)\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated Verilog: [Layer2](https://github.com/jfw225/mnist-cnn-fpga/blob/main/deployment/DE1-SoC_Computer_15_640_current/verilog/layer2.sv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<!-- container: dark -->\n",
    "#### Layer 3: Conv2DSum1D\n",
    "This layer is exactly the same as the **Conv2D** layer (section titled **Layer 1: Conv2D**). In fact, this layer runs $c=8$ iterations of **Conv2D** and takes the element-wise sum of those iterations.\n",
    "\n",
    "The 2D convolutional layer with a 1D sum has weights $W^3$ and biases $B^3$ that are defined by\n",
    "$$\\begin{align*}\n",
    "    & W^3:[x=2,y=2,z=8,c=8]=\\begin{bmatrix} W^3_1:[x,y,z] & \\dots & W^3_c:[x,y,z] \\end{bmatrix}, \\\\ \n",
    "    & B^3:[c=8]=\\begin{bmatrix} b_1 & \\dots & b_c \\end{bmatrix}.\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input and output arrays are defined by \n",
    "$$\\begin{align*}\n",
    "    & V_3^{in}:[n=13,n=13,c=8]=V_2^{out}, \\\\\n",
    "    & V_3^{out}:[n-1,n-1,c].\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mathematical Description\n",
    "Let $L^{i*}_1$ be a **Conv2D** layer with weights $W:[x,y,z]=W^3_{:,:,:,i}$ and biases $B$ s.t. $B$ is a $c$-length array of all zeros. Then we will apply $L^{i*}_1$ to each of the $0\\leq i\\leq c$ matrices of shape $(n,n)$ in $V_3^{in}$ and store the output in an output matrix `cout`. More rigidly, `cout` is defined by \n",
    "$$cout:[c,n-1,n-1,c]=\\begin{bmatrix} L^{1*}_1\\left(V_{3_{:,:,1}}^{in}\\right) & \\dots & L^{i*}_1\\left(V_{3_{:,:,i}}^{in}\\right) & \\dots & L^{c*}_1\\left(V_{3_{:,:,c}}^{in}\\right) \\end{bmatrix}$$\n",
    "for $i=1,\\dots,c$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then take the element-wise sum of each array in `cout` (note that the last dimension of `cout` is $c$) in addition to the $c$-length vector of biases in $B^3$. The output of this operation is the output of the layer and is thus stored in $V_3^{out}$:\n",
    "$$V_3^{out}:[n-1,n-1,c]=cout_1+\\dots+cout_i+\\dots+cout_c+B^3$$\n",
    "for $i=1,\\dots,c$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Programatic Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python\n",
    "import numpy as np\n",
    "\n",
    "def Conv2D(\n",
    "    V1in: np.ndarray[13, 13], \n",
    "    W1: np.ndarray[2, 2, 8], \n",
    "    B1: np.ndarray[8]\n",
    "):  \n",
    "    n, n = V1in.shape\n",
    "    x, y, z = W1.shape\n",
    "\n",
    "    # init the output array\n",
    "    V1out = np.ndarray[n - 1,  n - 1, z]  # (27, 27, 8)\n",
    "\n",
    "    for i in range(n - 1):  # rows if image\n",
    "        for j in range(n - 1):  # columns of image\n",
    "            # array of shape `(x, y)`\n",
    "            sub: np.ndarray[x, y] = V1in[i:i + x, j:j + y] \n",
    "\n",
    "            # vector of length `z`\n",
    "            convij: np.ndarray[z] = np.sum(sub * W1, axis=(0, 1))\n",
    "\n",
    "            V1out[i, j] = convij + B1\n",
    "\n",
    "    return V1out\n",
    "\n",
    "def Conv2DSum1D(\n",
    "    V3in: np.ndarray[13, 13, 8],\n",
    "    W3: np.ndarray[2, 2, 8, 8],\n",
    "    B3: np.ndarray[8]\n",
    "):\n",
    "    x, y, z, c = W3.shape\n",
    "    \n",
    "    cout = []\n",
    "    for i in range(c):\n",
    "        cout.append(Conv2D(\n",
    "            V3in[:, :, i], \n",
    "            W3[:, :, :, i], \n",
    "            [0 for _ in range(c)]\n",
    "        ))\n",
    "\n",
    "    V3out = sum(cout) + B3\n",
    "\n",
    "    return V3out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Verython Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python\n",
    "class Conv2DSum1D(Layer):\n",
    "    \"\"\"\n",
    "    img_array of size (n, n, c)\n",
    "    kernel_array of size (x, y, z, c)\n",
    "\n",
    "    img_i = img_array[:, :, cr]\n",
    "           = img_array[i + n * n * cr]\n",
    "    kernel_i = kernel_array[:, :, :, cr]\n",
    "             = kernel_array[i + x * y * z * cr]\n",
    "\n",
    "\n",
    "    where row counter cr is swept over\n",
    "    cr=0, ..., c - 1.\n",
    "\n",
    "    img of size (n, n)\n",
    "    kernel of size (x, y, z)\n",
    "\n",
    "    We have z=8 filters, each of which are x=2 by y=2\n",
    "    Let FIL_1 denote the first filter(i, j) using the notation above, then:\n",
    "    kernel = [ [f1      [h1\n",
    "                f2       h2\n",
    "                g1 ,     j1 ...\n",
    "                g2]      j2]       ]\n",
    "\n",
    "           = [FIL_1.T, FIL_2.T, ... , FIL_8.T]  --> this is hard to think about\n",
    "                                            since these filters are transposed\n",
    "\n",
    "    at each iteration i=1,..., n - 1 and j=1,..., n - 1:\n",
    "    sub(i, j) of size (x, y) is subset of the image\n",
    "    sub(i, j) = [[f1, ..., fx],\n",
    "                 [g1, ..., gy]]\n",
    "\n",
    "    kernel = [[ F1 = [o1, ..., oz],\n",
    "                ...\n",
    "                Fx = [p1, ..., pz]],\n",
    "              [ G1 = [q1, ..., qz],\n",
    "                ...\n",
    "                Gy = [r1, ..., rz]]\n",
    "\n",
    "    prod(i, j) = sub(i, j) * kernel\n",
    "               = [[ f1 * F1,\n",
    "                    ...\n",
    "                    fx * Fx],\n",
    "                  [ g1 * G1,\n",
    "                    gy * Gy]]\n",
    "    sum(i, j) = prod.sum(axis=(0, 1)) =\n",
    "        [\n",
    "            f1 * o1 + ... + fx * p1 + g1 * q1 + ... + gy * r1,\n",
    "            ...\n",
    "            f1 * oz + ... + fx * pz + g1 * qz + ... + gy * rz\n",
    "        ]\n",
    "\n",
    "    output is array of size (n - 1, n - 1, z) where\n",
    "    output[i, j] = sum(i, j)\n",
    "    ------------\n",
    "    This very abstract representation makes hard to develop the intuition,\n",
    "    let's ignore this for now\n",
    "    ------------\n",
    "    mat is a 2x2 slice of the image --> img[i:i+2, j:j+2]\n",
    "    Let's say:\n",
    "    mat = np.array([[[0.1],\n",
    "                     [0.5]],\n",
    "                     [[1.],\n",
    "                     [1.]]])\n",
    "    kernel = np.ones( (2,2,8) )\n",
    "\n",
    "    prod(i, j) = mat * kernel\n",
    "               = np.array([[[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
    "                            [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]],\n",
    "                            [[1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. ],\n",
    "                            [1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. ]]])\n",
    "    output(i, j) = np.array([2.6, 2.6, 2.6, 2.6, 2.6, 2.6, 2.6, 2.6])\n",
    "                                             --> we sum the columns\n",
    "\n",
    "    final sum\n",
    "    output of shape (o1, o2, c)\n",
    "    conv_out_arr of shape (c, o1, o2, c)\n",
    "\n",
    "    for flattened output out of len (o1 * o2 * c),\n",
    "    out[oc] = sum(conv_out_arr[i * o1 * o2 * c + oc])\n",
    "    for i=0, ..., c - 1,\n",
    "    for oc=0, ..., o1 * o2 * c - 1.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        int_width: BitWidth,\n",
    "        dec_width: BitWidth,\n",
    "        weights_np: np.ndarray,\n",
    "        biases_np: np.ndarray,\n",
    "        input_mem: M10K,\n",
    "        output_mem: M10K,\n",
    "        input_shape: Optional[InputShape],\n",
    "        output_shape: Optional[OutputShape]\n",
    "    ):\n",
    "\n",
    "        # create the signed mult and sigmoid modules\n",
    "        self.signed_mult = SignedMult(int_width, dec_width)\n",
    "\n",
    "        super().__init__(\n",
    "            int_width=int_width,\n",
    "            dec_width=dec_width,\n",
    "            weights_np=weights_np,\n",
    "            biases_np=biases_np,\n",
    "            input_mem=input_mem,\n",
    "            output_mem=output_mem,\n",
    "            input_shape=input_shape,\n",
    "            output_shape=output_shape,\n",
    "            objects=[self.signed_mult]\n",
    "        )\n",
    "\n",
    "        # make sure input data is signed\n",
    "        self.inp_data.signed = True\n",
    "\n",
    "        # make output data a wire\n",
    "        self.out_data.dtype = V_Reg\n",
    "\n",
    "        print(self.input_shape, weights_np.shape, self.output_shape)\n",
    "        n1, n2, c = self.input_shape\n",
    "        assert n1 == n2\n",
    "        n = n1\n",
    "\n",
    "        x, y, z, c = weights_np.shape\n",
    "\n",
    "        assert x == y, weights_np\n",
    "\n",
    "        *_, o1, o2, c = self.output_shape\n",
    "        assert o1 == o2\n",
    "\n",
    "        # the constant used to scale the inputs (>> 8 -> / 256)\n",
    "        self.input_scaler = 8\n",
    "\n",
    "        # store the target size (** MIGHT BE SOURCE OF ERROR)\n",
    "        self.target_size = n - 1\n",
    "        print(f\"{nameof(self)} Target Size: {self.target_size}\")\n",
    "\n",
    "        # the number of rows in the flattened weights\n",
    "        self.w_rows = x * x\n",
    "\n",
    "        # create registers used as iteration indices\n",
    "        # ti=0, ..., target_size - 1\n",
    "        self.ti = self.var(dtype=V_Reg,\n",
    "                           width=self.input_mem.addr_width,\n",
    "                           name=\"ti\")\n",
    "\n",
    "        # tj=0, ..., target_size - 1\n",
    "        self.tj = self.var(dtype=V_Reg,\n",
    "                           width=self.input_mem.addr_width,\n",
    "                           name=\"tj\")\n",
    "\n",
    "        # wc=0, ..., z - 1\n",
    "        self.wc = self.var(dtype=V_Reg,\n",
    "                           width=self.w_addr.width,\n",
    "                           name=\"wc\")\n",
    "\n",
    "        # cr=0, ..., c - 1\n",
    "        self.cr = self.var(dtype=V_Reg,\n",
    "                           width=self.input_mem.addr_width,\n",
    "                           name=\"cr\")\n",
    "\n",
    "        # oc=0, ..., o1 * o2 * c - 1 (output col)\n",
    "        self.oc = self.var(dtype=V_Reg,\n",
    "                           width=ceil(log2(c * o1 * o2 * c)),\n",
    "                           name=\"oc\")\n",
    "\n",
    "        # ii=0, ..., x - 1\n",
    "        self.ii = self.var(dtype=V_Reg,\n",
    "                           width=self.input_mem.addr_width,\n",
    "                           name=\"ii\")\n",
    "\n",
    "        # jj=0, ..., x - 1\n",
    "        self.jj = self.var(dtype=V_Reg,\n",
    "                           width=self.input_mem.addr_width,\n",
    "                           name=\"jj\")\n",
    "\n",
    "        # r=0, ..., x * x - 1\n",
    "        self.r = self.var(dtype=V_Reg,\n",
    "                          width=self.input_mem.addr_width,\n",
    "                          name=\"r\")\n",
    "\n",
    "        # create a register array for the sub image\n",
    "        self.sub = self.var(\n",
    "            dtype=V_RegArray,\n",
    "            width=self.width,\n",
    "            size=x * x,\n",
    "            signed=True,\n",
    "            name=\"sub_img\"\n",
    "        )\n",
    "\n",
    "        # holds the c elements of sum(i, j), used to sum\n",
    "        # over the c rows of outputs\n",
    "        self.sum_arr = self.var(\n",
    "            dtype=V_RegArray,\n",
    "            width=self.width,\n",
    "            size=c,\n",
    "            signed=True,\n",
    "            name=\"sum_arr\")\n",
    "\n",
    "        # create `self.w_rows` multiplier outputs\n",
    "        self.mult_outs = [self.var(dtype=V_Wire,\n",
    "                                   width=self.signed_mult.width,\n",
    "                                   signed=True,\n",
    "                                   name=f\"mult_out_{wr}\")\n",
    "                          for wr in range(self.w_rows)]\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(\n",
    "        x: np.ndarray,\n",
    "        weights_np: Weights,\n",
    "        biases_np: Biases\n",
    "    ):\n",
    "\n",
    "        *_, c = x.shape\n",
    "\n",
    "        # Z1 = np.array([convolve_flat(x[:, :, i], weights_np[:, :, :, i])\n",
    "        #                for i in range(c)])\n",
    "        Z1 = sum([convolve_flat(x[:, :, i], weights_np[:, :, :, i])\n",
    "                  for i in range(c)])\n",
    "\n",
    "        return Z1 + biases_np\n",
    "\n",
    "    def convert_model_params(\n",
    "        self,\n",
    "        int_width: BitWidth,\n",
    "        dec_width: BitWidth,\n",
    "        weights_np: np.ndarray,\n",
    "        biases_np: np.ndarray\n",
    "    ) -> Tuple[V_Array, V_Array]:\n",
    "\n",
    "        assert biases_np.ndim == 1, biases_np\n",
    "\n",
    "        w_flat = weights_np.flatten()\n",
    "\n",
    "        weights = V_Array(\n",
    "            module=self,\n",
    "            dtype=V_ParameterArray,\n",
    "            width=int_width + dec_width,\n",
    "            size=len(w_flat),\n",
    "            signed=True,\n",
    "            data=[V_FixedPoint(v, int_width, dec_width) for v in w_flat],\n",
    "            name=f\"conv2dsum1d_weights\"\n",
    "        )\n",
    "\n",
    "        biases = V_Array(\n",
    "            module=self,\n",
    "            dtype=V_ParameterArray,\n",
    "            width=int_width + dec_width,\n",
    "            size=len(biases_np),\n",
    "            signed=True,\n",
    "            data=[V_FixedPoint(v, int_width, dec_width)\n",
    "                  for v in biases_np],\n",
    "            name=f\"conv2dsum1d_biases\"\n",
    "        )\n",
    "\n",
    "        return weights, biases\n",
    "\n",
    "    def generate(self) -> V_Block:\n",
    "        x, y, z, c = self.weights_np.shape\n",
    "\n",
    "        *_, o1, o2, c = self.output_shape\n",
    "\n",
    "        vsm = V_StateMachine(_StReset, _StWaitValid, _StResetSumArr,\n",
    "                             _StResetSub, _StSetInpAddr, _StSubBuffer,\n",
    "                             _StSetSub, _StComputeConv, _StIncWeightIndices,\n",
    "                             _StIncTargetIndices, _StWriteData, _StWriteBuffer)\n",
    "\n",
    "        # instantiate x * x signed mult modules\n",
    "        mult = self.signed_mult\n",
    "        self.signed_mult_inss = [self.signed_mult.instantiate(\n",
    "            self,\n",
    "            (V_Empty(), mult.clk),\n",
    "            (V_Empty(), mult.reset),\n",
    "            (V_Empty(), mult.valid),\n",
    "            (V_Empty(), mult.done),\n",
    "            (V_Empty(), mult.ready),\n",
    "            (self.sub[wr], mult.input_ports[0]),\n",
    "            (self.weights[(self.wc * c) + self.cr +\n",
    "                          (wr * z * c)], mult.input_ports[1]),\n",
    "            (self.mult_outs[wr], mult.output_ports[0])\n",
    "        ) for wr in range(self.w_rows)]\n",
    "\n",
    "        return super().generate(vsm, V_Block(\n",
    "            \"// instantiate the multipliers\",\n",
    "            *[line for mult_ins in self.signed_mult_inss for line in mult_ins],\n",
    "\n",
    "        ))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Conv2DSum1D State Machine:\n",
    "img of size (n, n)\n",
    "kernel of size (x, y, z)\n",
    "\n",
    "\n",
    "first load each input into a local register array\n",
    "reasoning:\n",
    "    at each iteration, we need to get 4 new inputs from input memory. this\n",
    "    would take at least 5 cycles to set input addr and get new data\n",
    "\n",
    "    getting all the inputs into a reg array would allow us to get new values\n",
    "    in same cycle\n",
    "\n",
    "call this reg array `inp_reg`\n",
    "for iteration i=1,..., n - 1 and j=1,..., n - 1:\n",
    "filter(i, j) is of size (x, y)\n",
    "\n",
    "\n",
    "set the sub by\n",
    "for ti in range(target_size):\n",
    "    for tj in range(target_size):\n",
    "        sub[0:x * x - 1] = inp_reg[ti:ti + x, ti:ti + x]\n",
    "\n",
    "\n",
    "go straight to computing this the prod.sum:\n",
    "sum(i, j) = prod.sum(axis=(0, 1)) =\n",
    "        [\n",
    "            f1 * o1 + ... + fx * p1 + g1 * q1 + ... + gy * r1,\n",
    "            ...\n",
    "            f1 * oz + ... + fx * pz + g1 * qz + ... + gy * rz\n",
    "        ]\n",
    "        =\n",
    "        [\n",
    "            sub[0] * W[0 + 0 * z] + ... + sub[wr] * W[0 + wr * z],\n",
    "            sub[0] * W[1 + 0 * z] + ... + sub[wr] * W[1 + wr * z],\n",
    "            ...\n",
    "            sub[0] * W[wc + 0 * z] + ... + sub[wr] * W[wc + wr * z]\n",
    "        ]\n",
    "where wr=0, ..., x * x - 1 and is the row index and\n",
    "      wc=0, ...., z - 1\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class _StReset(V_State):\n",
    "    \"\"\"\n",
    "    init input read addr\n",
    "    init the bias addr\n",
    "    init output write addr\n",
    "    lower output write enable\n",
    "\n",
    "    init iteration variables\n",
    "\n",
    "    go to StWaitValid\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Conv2DSum1D) -> V_Block:\n",
    "\n",
    "        return V_Block(\n",
    "            m.inp_addr.set(m.input_mem.base_addr),\n",
    "            m.b_addr.set(V_Low),\n",
    "            m.out_addr.set(m.output_mem.base_addr),\n",
    "            m.out_we.set(V_Low),\n",
    "\n",
    "            m.ti.set(V_Low),\n",
    "            m.tj.set(V_Low),\n",
    "            m.wc.set(V_Low),\n",
    "\n",
    "            m.cr.set(V_Low),\n",
    "            m.oc.set(V_Low),\n",
    "\n",
    "            _StWaitValid\n",
    "        )\n",
    "\n",
    "\n",
    "class _StWaitValid(V_State):\n",
    "    \"\"\"\n",
    "    if (valid)\n",
    "        go to StInitInputReg\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Conv2DSum1D) -> V_Block:\n",
    "\n",
    "        return V_Block(\n",
    "            *V_If(m.valid)(\n",
    "\n",
    "                _StResetSumArr\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "class _StResetSumArr(V_State):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Conv2DSum1D) -> V_Block:\n",
    "        x, y, z, c = m.weights_np.shape\n",
    "\n",
    "        return V_Block(\n",
    "            *[m.sum_arr[i].set(V_Low) for i in range(c)],\n",
    "\n",
    "            _StResetSub\n",
    "        )\n",
    "\n",
    "\n",
    "class _StResetSub(V_State):\n",
    "    \"\"\"\n",
    "    reset the counters used for sub\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Conv2DSum1D) -> V_Block:\n",
    "        return V_Block(\n",
    "            m.ii.set(V_Low),\n",
    "            m.jj.set(V_Low),\n",
    "            m.r.set(V_Low),\n",
    "\n",
    "            _StSetInpAddr\n",
    "        )\n",
    "\n",
    "\n",
    "class _StSetInpAddr(V_State):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Conv2DSum1D) -> V_Block:\n",
    "        n = m.target_size + 1\n",
    "        x, y, z, c = m.weights_np.shape\n",
    "\n",
    "        return V_Block(\n",
    "            m.inp_addr.set(\n",
    "                (V_Par(m.ti + m.ii) * n * c) +\n",
    "                (V_Par(m.tj + m.jj) * c) +\n",
    "                m.cr\n",
    "            ),\n",
    "\n",
    "            _StSubBuffer\n",
    "        )\n",
    "\n",
    "\n",
    "class _StSubBuffer(V_State):\n",
    "    \"\"\"\n",
    "    delay 1 cycle\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Conv2DSum1D) -> V_Block:\n",
    "        return V_Block(\n",
    "\n",
    "            _StSetSub\n",
    "        )\n",
    "\n",
    "\n",
    "class _StSetSub(V_State):\n",
    "    \"\"\"\n",
    "    kernel of size (x, y, z, c)\n",
    "\n",
    "    set the sub by\n",
    "    for ti in range(target_size):\n",
    "        for tj in range(target_size):\n",
    "            sub[0:x * x - 1] = inp_reg[ti:ti + x, ti:ti + x]\n",
    "\n",
    "            set wc to zero\n",
    "\n",
    "            go to StComputeConv\n",
    "\n",
    "    inp_reg of size (n, n, c)\n",
    "    inp_reg[i, j, cr] = inp_reg[(i * n * c) + (j * c) + cr]\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Conv2DSum1D) -> V_Block:\n",
    "        # should be the first dim of the input shape\n",
    "        n = m.target_size + 1\n",
    "\n",
    "        x, y, z, c = m.weights_np.shape\n",
    "\n",
    "        max_ii = x - 1\n",
    "        max_jj = x - 1\n",
    "        max_r = x * x - 1\n",
    "        indices = [(ii * n * c, jj * c) for ii in range(x) for jj in range(x)]\n",
    "\n",
    "        return V_Block(\n",
    "            # *[m.sub[r].set(m.inp_reg[\n",
    "            #     (m.ti * n * c + ii) + (m.tj * c + jj) + m.cr]\n",
    "            # ) for r, (ii, jj) in enumerate(indices)],\n",
    "            # *[m.sub[r].set(m.inp_reg[m.tj + (jj + ii) + m.ti * n + (m.cr * n * n)])\n",
    "            #   for r, (ii, jj) in enumerate(indices)],\n",
    "\n",
    "            m.sub[m.r].set(m.inp_data),\n",
    "\n",
    "            *V_If(m.r == max_r)(\n",
    "                m.wc.set(V_Low),\n",
    "\n",
    "                _StComputeConv\n",
    "            ), *V_Else(\n",
    "                m.r.set(m.r + 1),\n",
    "\n",
    "                # dont need to handle the case of max_ii because m.r == max_r\n",
    "                *V_If(m.jj == max_jj)(\n",
    "                    m.ii.set(m.ii + 1),\n",
    "                    m.jj.set(V_Low)\n",
    "                ), *V_Else(\n",
    "                    m.jj.set(m.jj + 1)\n",
    "                ),\n",
    "\n",
    "                _StSetInpAddr\n",
    "            )\n",
    "\n",
    "            # m.wc.set(V_Low),\n",
    "\n",
    "            # _StComputeConv\n",
    "        )\n",
    "\n",
    "\n",
    "class _StComputeConv(V_State):\n",
    "    \"\"\"\n",
    "    store the multiplier output in the convolutional output array\n",
    "    go to StComputeSig\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Conv2DSum1D) -> V_Block:\n",
    "\n",
    "        return V_Block(\n",
    "            \"// assign the output of the convolution\",\n",
    "            # m.conv_out_arr[m.oc].set(\n",
    "            #     V_Sum(*m.mult_outs, m.biases[m.wc])),\n",
    "            # m.conv_out_arr[m.oc].set(V_Sum(*m.mult_outs)),\n",
    "            m.sum_arr[m.wc].set(V_Sum(m.sum_arr[m.wc], *m.mult_outs)),\n",
    "            # m.out_we.set(V_High),\n",
    "\n",
    "            _StIncWeightIndices\n",
    "        )\n",
    "\n",
    "\n",
    "class _StIncWeightIndices(V_State):\n",
    "    \"\"\"\n",
    "    out_we.set(V_Low),\n",
    "\n",
    "    if (wc == w_rows - 1)\n",
    "        set wc to 0\n",
    "\n",
    "        if (m.oc = c * o1 * o2 * c - 1)\n",
    "            set m.oc to 0\n",
    "\n",
    "            go to StIncTargetIndices\n",
    "        else\n",
    "            inc m.oc\n",
    "\n",
    "            go to StIncTargetIndices\n",
    "    else\n",
    "        inc wc\n",
    "        inc m.oc\n",
    "\n",
    "        go to StComputeConv\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Conv2DSum1D) -> V_Block:\n",
    "        *_, o1, o2, c = m.output_shape\n",
    "        max_oc = c * o1 * o2 * c - 1\n",
    "\n",
    "        # max_rows = m.w_rows - 1\n",
    "        x, y, z, c = m.weights_np.shape\n",
    "        max_cols = z - 1\n",
    "\n",
    "        return V_Block(\n",
    "\n",
    "            # m.out_we.set(V_Low),\n",
    "            *V_If(m.wc == max_cols)(\n",
    "                m.wc.set(V_Low),\n",
    "\n",
    "                *V_If(m.oc == max_oc)(\n",
    "                    m.oc.set(V_Low),\n",
    "\n",
    "                    _StIncTargetIndices\n",
    "                ), *V_Else(\n",
    "                    # m.out_addr.set(m.out_addr + 1),\n",
    "                    m.oc.set(m.oc + 1),\n",
    "\n",
    "                    _StIncTargetIndices\n",
    "                )\n",
    "            ), *V_Else(\n",
    "                m.wc.set(m.wc + 1),\n",
    "                m.oc.set(m.oc + 1),\n",
    "                # m.out_addr.set(m.out_addr + 1),\n",
    "\n",
    "                _StComputeConv\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "class _StIncTargetIndices(V_State):\n",
    "    \"\"\"\n",
    "    if (m.cr == c - 1)\n",
    "        set m.cr to 0\n",
    "\n",
    "        if (m.tj == m.target_size - 1)\n",
    "            set m.tj to 0\n",
    "\n",
    "            if (m.ti == m.target_size - 1)\n",
    "                set m.ti to 0\n",
    "                raise the output write enable\n",
    "\n",
    "                go to _StSum1D\n",
    "            else\n",
    "                inc m.ti\n",
    "\n",
    "                go to _StResetSumArr\n",
    "        else\n",
    "            inc m.tj\n",
    "\n",
    "            go to _StResetSumArr\n",
    "\n",
    "    else\n",
    "        inc m.cr\n",
    "\n",
    "        go to _StResetSub\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Conv2DSum1D) -> V_Block:\n",
    "        max_iter = m.target_size - 1\n",
    "\n",
    "        x, y, z, c = m.weights_np.shape\n",
    "        max_cr = c - 1\n",
    "\n",
    "        return V_Block(\n",
    "            *V_If(m.cr == max_cr)(\n",
    "                m.cr.set(V_Low),\n",
    "\n",
    "\n",
    "                *V_If(m.tj == max_iter)(\n",
    "                    m.tj.set(V_Low),\n",
    "\n",
    "                    *V_If(m.ti == max_iter)(\n",
    "                        m.ti.set(V_Low),\n",
    "\n",
    "                    ), *V_Else(\n",
    "                        m.ti.set(m.ti + 1),\n",
    "\n",
    "                    )\n",
    "                ), *V_Else(\n",
    "                    m.tj.set(m.tj + 1),\n",
    "\n",
    "                ),\n",
    "\n",
    "                _StWriteData\n",
    "            ), *V_Else(\n",
    "                m.cr.set(m.cr + 1),\n",
    "\n",
    "                _StResetSub\n",
    "            ),\n",
    "        )\n",
    "\n",
    "\n",
    "class _StWriteData(V_State):\n",
    "\n",
    "    def generate(self, m: Conv2DSum1D) -> V_Block:\n",
    "        max_out_addr = m.output_mem.size\n",
    "        x, y, z, c = m.weights_np.shape\n",
    "        max_wc = z\n",
    "\n",
    "        return V_Block(\n",
    "            # m.out_we.set(V_Low),\n",
    "\n",
    "            m.out_data.set(m.sum_arr[m.wc] + m.biases[m.wc]),\n",
    "\n",
    "            *V_If(m.out_addr == max_out_addr)(\n",
    "\n",
    "                V_StDone\n",
    "            ), *V_Else(\n",
    "                *V_If(m.wc == max_wc)(\n",
    "                    m.wc.set(V_Low),\n",
    "\n",
    "                    _StResetSumArr\n",
    "                ), *V_Else(\n",
    "\n",
    "                    m.out_we.set(V_High),\n",
    "                    _StWriteBuffer\n",
    "                )\n",
    "            )\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "class _StWriteBuffer(V_State):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Conv2DSum1D) -> V_Block:\n",
    "\n",
    "        return V_Block(\n",
    "            m.out_we.set(V_Low),\n",
    "            # m.out_we.set(V_High),\n",
    "            m.out_addr.set(m.out_addr + 1),\n",
    "            m.wc.set(m.wc + 1),\n",
    "\n",
    "            _StWriteData\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated Verilog: [Layer3](https://github.com/jfw225/mnist-cnn-fpga/blob/main/deployment/DE1-SoC_Computer_15_640_current/verilog/layer3.sv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<!-- container: default -->\n",
    "#### Layer 4: MaxpoolFC\n",
    "The last layer is the same as **Maxpool** (as in the layer detailed in the section titled **Layer 2: Maxpool**) with one extra step. Unlike **Maxpool**, this layer has weights and biases defined by \n",
    "$$\\begin{align*}\n",
    "    W^4:[m=1352, f=10] && B^4:[f=10].\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inputs and outputs of this layer are defined by \n",
    "$$\\begin{align*}\n",
    "    & V_4^{in}:[x=12,y=12,n=8]=V_3^{out}, \\\\\n",
    "    & V_4^{out}:[f=10].\n",
    "    & V_4^{out}:[\\lceil x/2\\rceil=6, \\lceil y/2\\rceil=6, n=8].\n",
    "\\end{align*}$$\n",
    "where $\\lceil r\\rceil$ is $r$ rounded up to the nearest integer for some $r\\in\\mathbb{R}$.\n",
    "We also use $s=2$ for the stride hyperparameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Mathematical Description\n",
    "This layer is fairly simple. We start by applying the **Maxpool** layer with stride $s=2$ to the input and storing it in `mpout`, or rather\n",
    "$$mpout:[\\lceil x/2\\rceil=6, \\lceil y/2\\rceil=6, n=8]=L_2\\left(V_4^{in}\\right)$$\n",
    "where $\\lceil r\\rceil$ is $r$ rounded up to the nearest integer for some $r\\in\\mathbb{R}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then flatten `mpout` to make it single-dimensional, take the row-wise dot product and add in the biases to get our fully-connected output:\n",
    "$$V_4^{out}:[f=10]=\n",
    "\\begin{bmatrix} \n",
    "    B^4_1 + \\sum_{j=1}^m V_{4_j}^{in}\\cdot W^4_{j,1} \\\\\n",
    "    \\vdots \\\\\n",
    "    B^4_i + \\sum_{j=1}^m V_{4_j}^{in}\\cdot W^4{j,i} \\\\ \n",
    "    \\vdots \\\\ \n",
    "    B^4_f + \\sum_{j=1}^m V_{4_j}^{in}\\cdot W^4_{j,f}\n",
    "\\end{bmatrix}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Programatic Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python\n",
    "import numpy as np\n",
    "\n",
    "def Maxpool(V2in: np.ndarray[27, 27, 8], s=2):\n",
    "    x, y, n = image.shape\n",
    "\n",
    "    V2out = np.ndarray[x // 2, y // 2, n]\n",
    "\n",
    "    # slide the window over every part of the image using stride s\n",
    "    # take the maximum value at each step\n",
    "    i = 0\n",
    "\n",
    "    # slide the max pooling window vertically across the image\n",
    "    while i + s <= x:\n",
    "        j = 0\n",
    "\n",
    "        # slide the max pooling window horizontally across the image\n",
    "        while j + s <= y:\n",
    "            # choose the max value in the window at each step\n",
    "            maxij = np.max(V2in[i:i + s, j:j + s], axis=(0, 1))\n",
    "\n",
    "            # store it to output matrix\n",
    "            V2out[i // s, j // s] = maxij\n",
    "            \n",
    "            # increment `j`\n",
    "            j += s\n",
    "\n",
    "        # increment `i`\n",
    "        i += s\n",
    "\n",
    "    return V2out\n",
    "\n",
    "def MaxpoolFC(\n",
    "    V4in: np.ndarray[12, 12, 8],\n",
    "    W4: np.ndarray[1352, 10],\n",
    "    B4: np.ndarray[10],\n",
    "    s=2\n",
    "):\n",
    "    mp = Maxpool(V4in, s)\n",
    "\n",
    "    return mp.reshape(-1).dot(W4) + B4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Verython Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python\n",
    "class Maxpool_FC(Layer):\n",
    "    \"\"\"\n",
    "    Let the input to this layer be \n",
    "\n",
    "    mp_input of size (y, x, n)\n",
    "    window is of size (f * f * n)\n",
    "\n",
    "    window = [[\n",
    "        A1 = [o1, ..., on],\n",
    "        ...,\n",
    "        Af = [p1, ..., pn]\n",
    "    ], [\n",
    "        B1 = [q1, ..., qn],\n",
    "        ...,\n",
    "        Bf = [r1, ..., rn]\n",
    "    ]]\n",
    "\n",
    "    the output at iteration (i, j) is the columnwise max of \n",
    "    [A1, ..., Af, B1, ..., Bf], or rather, \n",
    "    max(i, j) of size (n) = [\n",
    "        max(o1, ..., p1, q1, ..., r1),\n",
    "        ...,\n",
    "        max(on, ..., pn, qn, ..., rn)\n",
    "    ] = [\n",
    "        max(\n",
    "            window[0 + 0 * z * z] \n",
    "            + ... + window[0 + wr * z * z] + ... +\n",
    "            window[0 + (z * z - 1) * z * z]\n",
    "        ), ..., \n",
    "        max(\n",
    "            window[wc + 0 * z * z] \n",
    "            + ... + window[wc + wr * z * z] + ... +\n",
    "            window[wc + (z * z - 1) * z * z]\n",
    "        ), ..., \n",
    "        max(\n",
    "            window[(n - 1) + 0 * z * z] \n",
    "            + ... + window[(n - 1) + wr * z * z] + ... +\n",
    "            window[(n - 1) + (z * z - 1) * z * z]\n",
    "        )\n",
    "        max(window[wc + wr * z * z])\n",
    "    ]\n",
    "\n",
    "    where wc=0, ..., n - 1 is the column sweep and \n",
    "    wr=0, ..., z * z - 1 is the row sweep.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        int_width: BitWidth,\n",
    "        dec_width: BitWidth,\n",
    "        weights_np: np.ndarray,\n",
    "        biases_np: np.ndarray,\n",
    "        input_mem: M10K,\n",
    "        output_mem: M10K,\n",
    "        input_shape: Optional[InputShape],\n",
    "        output_shape: Optional[OutputShape]\n",
    "    ):\n",
    "        # the number of terms used in the exponent taylor series approximation\n",
    "        self.exp_num_terms = 10\n",
    "\n",
    "        # create the max. mult, exponential, and div modules\n",
    "        self.signed_max = SignedMax(int_width, dec_width)\n",
    "        self.signed_mult = SignedMult(int_width, dec_width)\n",
    "\n",
    "        super().__init__(\n",
    "            int_width=int_width,\n",
    "            dec_width=dec_width,\n",
    "            weights_np=weights_np,\n",
    "            biases_np=biases_np,\n",
    "            input_mem=input_mem,\n",
    "            output_mem=output_mem,\n",
    "            input_shape=input_shape,\n",
    "            output_shape=output_shape,\n",
    "            objects=[self.signed_max, self.signed_mult]\n",
    "        )\n",
    "\n",
    "        # store f and stride values\n",
    "        self._f = 2\n",
    "        self._s = 2\n",
    "\n",
    "        # we assume the f is even for now\n",
    "        assert self._f % 2 == 0, self._f\n",
    "\n",
    "        # create a register array for the sliding window\n",
    "        self.window = self.var(dtype=V_RegArray,\n",
    "                               width=self.width,\n",
    "                               size=self.f * self.f * self.n,\n",
    "                               signed=True,\n",
    "                               name=\"window\")\n",
    "\n",
    "        # create a register for the output of the maxpool\n",
    "        self.mp_out = self.var(dtype=V_RegArray,\n",
    "                               width=self.width,\n",
    "                               size=(self.y // 2) * (self.x // 2) * self.n,\n",
    "                               signed=True,\n",
    "                               name=\"mp_out\")\n",
    "\n",
    "        # create iteration variables as in `maxpool_flat`\n",
    "        self.curr_y = self.var(dtype=V_Reg,\n",
    "                               width=self.input_mem.addr_width,\n",
    "                               name=\"curr_y\")\n",
    "        self.out_y = self.var(dtype=V_Reg,\n",
    "                              width=ceil(log2(self.mp_out.size)),\n",
    "                              name=\"out_y\")\n",
    "\n",
    "        self.curr_x = self.var(dtype=V_Reg,\n",
    "                               width=self.input_mem.addr_width,\n",
    "                               name=\"curr_x\")\n",
    "        self.out_x = self.var(dtype=V_Reg,\n",
    "                              width=ceil(log2(self.mp_out.size)),\n",
    "                              name=\"out_x\")\n",
    "\n",
    "        # jj=0, ..., f - 1\n",
    "        self.jj = self.var(dtype=V_Reg,\n",
    "                           width=self.input_mem.addr_width,\n",
    "                           name=\"jj\")\n",
    "\n",
    "        # ii=0, ..., f - 1\n",
    "        self.ii = self.var(dtype=V_Reg,\n",
    "                           width=self.input_mem.addr_width,\n",
    "                           name=\"ii\")\n",
    "\n",
    "        # kk=0, ..., n - 1\n",
    "        self.kk = self.var(dtype=V_Reg,\n",
    "                           width=self.input_mem.addr_width,\n",
    "                           name=\"kk\")\n",
    "\n",
    "        # ww=0, ..., f * f * n - 1\n",
    "        self.ww = self.var(dtype=V_Reg,\n",
    "                           width=ceil(log2(self.window.size)),\n",
    "                           name=\"ww\")\n",
    "\n",
    "        # wc=0, ..., n - 1\n",
    "        self.wc = self.var(dtype=V_Reg,\n",
    "                           width=self.output_mem.addr_width,\n",
    "                           name=\"wc\")\n",
    "\n",
    "        # wr=0, ..., f * f - 1\n",
    "        self.wr = self.var(dtype=V_Reg,\n",
    "                           width=ceil(log2(self.window.size)),\n",
    "                           name=\"wr\")\n",
    "\n",
    "        # holds the output of the signed max module\n",
    "        self.max_out = self.var(dtype=V_Wire,\n",
    "                                width=self.width,\n",
    "                                signed=True,\n",
    "                                name=\"max_out\")\n",
    "\n",
    "        # define a list to hold the output of the top level max moudle instances\n",
    "        # self.max_outputs[wc] holds the max of window column wc\n",
    "        self.max_outputs = list()\n",
    "\n",
    "        # define a list to hold the max module instances\n",
    "        self.max_instances = list()\n",
    "\n",
    "        # configure the logic for the max functionality\n",
    "        self._configure_max_logic()\n",
    "\n",
    "        # create variable to hold the value of the dot product\n",
    "        self.dp = self.add_var(self.signed_mult.out,\n",
    "                               dtype=V_Reg, name=\"dot_product\")\n",
    "\n",
    "        # create variable to hold the output of the multiplier\n",
    "        self.prod = self.add_var(self.signed_mult.out,\n",
    "                                 dtype=V_Wire, name=\"prod\")\n",
    "\n",
    "    @property\n",
    "    def f(self):\n",
    "        \"\"\"\n",
    "        The `f` parameter in `maxpool_flat`. \n",
    "        TODO: KEN COME BACK AND EXPLAIN THIS\n",
    "        \"\"\"\n",
    "\n",
    "        return self._f\n",
    "\n",
    "    @property\n",
    "    def s(self):\n",
    "        \"\"\"\n",
    "        The stride parameter in `maxpool_flat`.\n",
    "        \"\"\"\n",
    "\n",
    "        return self._s\n",
    "\n",
    "    @property\n",
    "    def y(self):\n",
    "        \"\"\"\n",
    "        Input array is of size `(y, x, n)`.\n",
    "        \"\"\"\n",
    "\n",
    "        y, x, n = self.input_shape\n",
    "\n",
    "        return y\n",
    "\n",
    "    @property\n",
    "    def x(self):\n",
    "        \"\"\"\n",
    "        Input array is of size `(y, x, n)`.\n",
    "        \"\"\"\n",
    "\n",
    "        y, x, n = self.input_shape\n",
    "\n",
    "        return x\n",
    "\n",
    "    @property\n",
    "    def n(self):\n",
    "        \"\"\"\n",
    "        Input array is of size `(y, x, n)`.\n",
    "        \"\"\"\n",
    "\n",
    "        y, x, n = self.input_shape\n",
    "\n",
    "        return n\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(\n",
    "        x: np.ndarray,\n",
    "        weights_np: Weights,\n",
    "        biases_np: Biases\n",
    "    ):\n",
    "\n",
    "        Z2 = maxpool_flat(x)\n",
    "        Z3 = Z2.reshape(-1).dot(weights_np)\n",
    "\n",
    "        return Z3 + biases_np\n",
    "        # return softmax(Z3 + biases_np)\n",
    "\n",
    "    def convert_model_params(\n",
    "        self,\n",
    "        int_width: BitWidth,\n",
    "        dec_width: BitWidth,\n",
    "        weights_np: np.ndarray,\n",
    "        biases_np: np.ndarray\n",
    "    ) -> Tuple[V_Array, V_Array]:\n",
    "\n",
    "        assert biases_np.ndim == 1, biases_np\n",
    "\n",
    "        w_flat = weights_np.T.flatten()\n",
    "\n",
    "        weights = V_Array(\n",
    "            module=self,\n",
    "            dtype=V_ParameterArray,\n",
    "            width=int_width + dec_width,\n",
    "            size=len(w_flat),\n",
    "            signed=True,\n",
    "            data=[V_FixedPoint(v, int_width, dec_width) for v in w_flat],\n",
    "            name=f\"maxpool_weights\"\n",
    "        )\n",
    "\n",
    "        biases = V_Array(\n",
    "            module=self,\n",
    "            dtype=V_ParameterArray,\n",
    "            width=int_width + dec_width,\n",
    "            size=len(biases_np),\n",
    "            signed=True,\n",
    "            data=[V_FixedPoint(v, int_width, dec_width)\n",
    "                  for v in biases_np],\n",
    "            name=f\"maxpool_biases\"\n",
    "        )\n",
    "\n",
    "        return weights, biases\n",
    "\n",
    "    def generate(self) -> V_Block:\n",
    "        mult = self.signed_mult\n",
    "\n",
    "        vsm = V_StateMachine(_StReset, _StWaitValid, _StResetWindow,\n",
    "                             _StSetInpAddr, _StWindowBuffer, _StSetWindow,\n",
    "                             _StFindMax, _StIncMaxpool, _StWaitDotProduct, _StWriteData)\n",
    "\n",
    "        return super().generate(vsm, V_Block(\n",
    "            \"// instantiate the signed maximum modules\",\n",
    "            *[line for sm_ins in self.max_instances for line in sm_ins],\n",
    "\n",
    "            \"\\n// instantiate the multiplier\",\n",
    "            *mult.instantiate(\n",
    "                self,\n",
    "                (V_Empty(), mult.clk),\n",
    "                (V_Empty(), mult.reset),\n",
    "                (V_Empty(), mult.valid),\n",
    "                (V_Empty(), mult.done),\n",
    "                (V_Empty(), mult.ready),\n",
    "                (self.mp_out[self.out_x], mult.input_ports[0]),\n",
    "                (self.w_data, mult.input_ports[1]),\n",
    "                (self.prod, mult.output_ports[0])\n",
    "            ),\n",
    "        ))\n",
    "\n",
    "    def _configure_max_logic(self) -> None:\n",
    "        \"\"\"\n",
    "        Configures the layer to be capable of handling the maximum \n",
    "        functionality for the window as described in _StFindMax. \n",
    "        \"\"\"\n",
    "\n",
    "        # localize `self.signed_max` for less typing\n",
    "        sm = self.signed_max\n",
    "\n",
    "        # create pairings for the maximum logic\n",
    "        inds = np.arange(self.f * self.f *\n",
    "                         self.n).reshape(self.f * self.f, self.n)\n",
    "\n",
    "        def create_pairs(indices):\n",
    "            # indices should always contain at least one\n",
    "            n = len(indices)\n",
    "            assert n > 0, indices\n",
    "            if n == 1:\n",
    "                return (*indices, None)\n",
    "            elif n == 2:\n",
    "                return (*indices,)\n",
    "\n",
    "            return (create_pairs(indices[:2]), create_pairs(indices[2:]))\n",
    "\n",
    "        def create_max_instances(pairs):\n",
    "            \"\"\"\n",
    "            Recursive function that creates the required instances of \n",
    "            `SignedMax`. Each iteration returns a reference to a register in \n",
    "            `self.window` or creates a `SignedMax` instance and returns a wire \n",
    "            connected to its output. \n",
    "            \"\"\"\n",
    "\n",
    "            A, B = pairs\n",
    "\n",
    "            if isinstance(A, int):\n",
    "                # if A is an int, B can either be an int or None\n",
    "                assert isinstance(B, int) or B is None, B\n",
    "\n",
    "                # if B is None, we simply return the window register value\n",
    "                if B is None:\n",
    "                    return self.window[A]\n",
    "\n",
    "                # otherwise, we set A and B to their register references\n",
    "                A, B = self.window[A], self.window[B]\n",
    "\n",
    "            # otherwise, A and B must be pairs\n",
    "            else:\n",
    "                assert not isinstance(B, int) and B is not None, B\n",
    "\n",
    "                # get the corresponding output wires of pairs A and B\n",
    "                A, B = create_max_instances(A), create_max_instances(B)\n",
    "\n",
    "            # create an output wire and an instance that computes max(A, B)\n",
    "            out = self.var(dtype=V_Wire,\n",
    "                           width=self.width,\n",
    "                           signed=True,\n",
    "                           name=f\"max_logic_{id_generator()}\")\n",
    "\n",
    "            self.max_instances.append(sm.instantiate(\n",
    "                self,\n",
    "                (V_Empty(), sm.clk),\n",
    "                (V_Empty(), sm.reset),\n",
    "                (V_Empty(), sm.valid),\n",
    "                (V_Empty(), sm.done),\n",
    "                (V_Empty(), sm.ready),\n",
    "                (A, sm.input_ports[0]),\n",
    "                (B, sm.input_ports[1]),\n",
    "                (out, sm.output_ports[0])\n",
    "            ))\n",
    "\n",
    "            # return the output wire\n",
    "            return out\n",
    "\n",
    "        # transpose because we are taking the column-wise maximum in the window\n",
    "        for col in inds.T:\n",
    "            pairs = create_pairs([*map(int, col)])\n",
    "            out = create_max_instances(pairs)\n",
    "            self.max_outputs.append(out)\n",
    "\n",
    "\n",
    "class _StReset(V_State):\n",
    "    \"\"\"\n",
    "    init input read addr\n",
    "    init weights addr to base\n",
    "    init biases addr to base\n",
    "    init output write addr\n",
    "    lower output write enable\n",
    "\n",
    "    init iteration variables\n",
    "\n",
    "    init dot product and exp sum\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Maxpool_FC) -> V_Block:\n",
    "\n",
    "        return V_Block(\n",
    "            m.inp_addr.set(m.input_mem.base_addr),\n",
    "            m.w_addr.set(V_Low),\n",
    "            m.b_addr.set(V_Low),\n",
    "            m.out_addr.set(m.output_mem.base_addr),\n",
    "            m.out_we.set(V_Low),\n",
    "\n",
    "            m.curr_y.set(V_Low),\n",
    "            m.out_y.set(V_Low),\n",
    "            m.curr_x.set(V_Low),\n",
    "            m.out_x.set(V_Low),\n",
    "\n",
    "            m.dp.set(V_Low),\n",
    "\n",
    "            _StWaitValid\n",
    "        )\n",
    "\n",
    "\n",
    "class _StWaitValid(V_State):\n",
    "    \"\"\"\n",
    "    if (valid)\n",
    "        go to StInitInputReg\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Maxpool_FC) -> V_Block:\n",
    "\n",
    "        return V_Block(\n",
    "            *V_If(m.valid)(\n",
    "\n",
    "                _StResetWindow\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "class _StResetWindow(V_State):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Maxpool_FC) -> V_Block:\n",
    "        return V_Block(\n",
    "            m.jj.set(V_Low),\n",
    "            m.ii.set(V_Low),\n",
    "            m.kk.set(V_Low),\n",
    "            m.ww.set(V_Low),\n",
    "\n",
    "            _StSetInpAddr\n",
    "        )\n",
    "\n",
    "\n",
    "class _StSetInpAddr(V_State):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Maxpool_FC) -> V_Block:\n",
    "\n",
    "        return V_Block(\n",
    "            m.inp_addr.set(\n",
    "                (V_Par(m.curr_y + m.jj) * m.x * m.n) +\n",
    "                (V_Par(m.curr_x + m.ii) * m.n) +\n",
    "                m.kk),\n",
    "\n",
    "            _StWindowBuffer\n",
    "        )\n",
    "\n",
    "\n",
    "class _StWindowBuffer(V_State):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Maxpool_FC) -> V_Block:\n",
    "\n",
    "        return V_Block(\n",
    "\n",
    "            _StSetWindow\n",
    "        )\n",
    "\n",
    "\n",
    "class _StSetWindow(V_State):\n",
    "    \"\"\"\n",
    "    set window = inp_reg[curr_y:curr_y + f, curr_x:curr_x + f]\n",
    "\n",
    "    inp_reg of size(y, x, n)\n",
    "    inp_reg[j, i, k] = inp_reg[(j * x * n) + (i * n) + k]\n",
    "\n",
    "    need to sweep\n",
    "    j=curr_y, ..., curr_y + f\n",
    "    i=curr_x, ..., curr_x + f\n",
    "    k=0, ..., n\n",
    "\n",
    "    go to _StFindMax\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Maxpool_FC) -> V_Block:\n",
    "        max_jj = m.f - 1\n",
    "        max_ii = m.f - 1\n",
    "        max_kk = m.n - 1\n",
    "        max_ww = m.f * m.f * m.n - 1\n",
    "\n",
    "        return V_Block(\n",
    "            m.window[m.ww].set(m.inp_data),\n",
    "\n",
    "            *V_If(m.ww == max_ww)(\n",
    "\n",
    "                _StFindMax\n",
    "            ), *V_Else(\n",
    "                m.ww.set(m.ww + 1),\n",
    "\n",
    "                *V_If(m.kk == max_kk)(\n",
    "                    m.kk.set(V_Low),\n",
    "\n",
    "                    # dont need to set jj low because that is case\n",
    "                    # where m.ww == max_ww\n",
    "                    *V_If(m.ii == max_ii)(\n",
    "                        m.ii.set(V_Low),\n",
    "                        m.jj.set(m.jj + 1)\n",
    "                    ), *V_Else(\n",
    "                        m.ii.set(m.ii + 1)\n",
    "                    )\n",
    "                ), *V_Else(\n",
    "                    m.kk.set(m.kk + 1)\n",
    "                ),\n",
    "\n",
    "                _StSetInpAddr\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "class _StFindMax(V_State):\n",
    "    \"\"\"\n",
    "    assign each of the column-wise maximums to the mp_out register\n",
    "\n",
    "    mp_out of size (y // 2, x // 2, n)\n",
    "\n",
    "    mp_out[(out_y * x // 2 * n) + (out_x * n) + wc] = max_outputs[wc]\n",
    "    for window column index wc=0,..., n - 1.\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Maxpool_FC) -> V_Block:\n",
    "\n",
    "        return V_Block(\n",
    "            *[m.mp_out[\n",
    "                (m.out_y * (m.x // 2) * m.n) + (m.out_x * m.n) + wc\n",
    "            ].set(m.max_outputs[wc])\n",
    "                for wc in range(m.n)],\n",
    "\n",
    "            _StIncMaxpool\n",
    "        )\n",
    "\n",
    "\n",
    "class _StIncMaxpool(V_State):\n",
    "    \"\"\"\n",
    "    set each of the previously set mp_outs to to themselves\n",
    "\n",
    "    if (curr_x <= x - s - f)\n",
    "        set curr_x to 0\n",
    "        set out_x to 0\n",
    "\n",
    "        if (curr_y <= y - s - f)\n",
    "            go to _StDotProduct\n",
    "        else\n",
    "            inc curr_y by s\n",
    "            inc out_y by 1\n",
    "\n",
    "            go to _StSetWindow\n",
    "\n",
    "    else\n",
    "        inc curr_x by s\n",
    "        inc out_x\n",
    "\n",
    "        go to _StSetWindow\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Maxpool_FC) -> V_Block:\n",
    "        max_y = m.y - m.s - m.f\n",
    "        max_x = m.x - m.s - m.f\n",
    "\n",
    "        print(max_y, max_x)\n",
    "\n",
    "        inds = [(m.out_y * (m.x // 2) * m.n) +\n",
    "                (m.out_x * m.n) + wc for wc in range(m.n)]\n",
    "\n",
    "        return V_Block(\n",
    "            *[m.mp_out[ind].set(m.mp_out[ind]) for ind in inds],\n",
    "\n",
    "            *V_If(m.curr_x > max_x)(\n",
    "                m.curr_x.set(V_Low),\n",
    "                m.out_x.set(V_Low),\n",
    "\n",
    "                *V_If(m.curr_y > max_y)(\n",
    "\n",
    "                    _StWaitDotProduct\n",
    "                ), *V_Else(\n",
    "                    m.curr_y.set(m.curr_y + m.s),\n",
    "                    m.out_y.set(m.out_y + 1),\n",
    "\n",
    "                    _StResetWindow\n",
    "                )\n",
    "            ), *V_Else(\n",
    "                m.curr_x.set(m.curr_x + m.s),\n",
    "                m.out_x.set(m.out_x + 1),\n",
    "\n",
    "                _StResetWindow\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "class _StWaitDotProduct(V_State):\n",
    "    \"\"\"\n",
    "    ** use out_x to iterate over the mp_out array\n",
    "\n",
    "    - add prod to dot product\n",
    "\n",
    "    - if (out_x == max - 1)\n",
    "        - inc weights addr\n",
    "\n",
    "        - raise the output write enable\n",
    "        - set the output data to dp + prod + bias\n",
    "\n",
    "        - go to StWaitExponential\n",
    "    - else\n",
    "        - inc out x\n",
    "        - inc weights addr\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Maxpool_FC) -> V_Block:\n",
    "        max_mp_out_addr = m.mp_out.size - 1\n",
    "\n",
    "        return V_Block(\n",
    "            m.dp.set(m.dp + m.prod),\n",
    "            \"\\n\",\n",
    "            *V_If(m.out_x == max_mp_out_addr)(\n",
    "                m.w_addr.set(m.w_addr + 1),\n",
    "                m.out_we.set(V_High),\n",
    "                m.out_data.set(m.dp + m.prod + m.biases[m.out_addr]),\n",
    "\n",
    "                _StWriteData\n",
    "            ), *V_Else(\n",
    "                m.out_x.set(m.out_x + 1),\n",
    "                m.w_addr.set(m.w_addr + 1),\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "class _StWriteData(V_State):\n",
    "    \"\"\"\n",
    "    lower output write enable\n",
    "    clear out_x\n",
    "    clear dot product\n",
    "\n",
    "    if (output addr == max)\n",
    "        go to StDone\n",
    "    else\n",
    "        inc out addr\n",
    "\n",
    "        go to _StWaitDotProduct\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Maxpool_FC) -> V_Block:\n",
    "        max_out_addr = m.output_mem.size - 1\n",
    "\n",
    "        return V_Block(\n",
    "            m.out_we.set(V_Low),\n",
    "            m.out_x.set(V_Low),\n",
    "            m.dp.set(V_Low),\n",
    "\n",
    "            *V_If(m.out_addr == max_out_addr)(\n",
    "\n",
    "                V_StDone\n",
    "            ), *V_Else(\n",
    "                m.out_addr.set(m.out_addr + 1),\n",
    "\n",
    "                _StWaitDotProduct\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated Verilog: [Layer4](https://github.com/jfw225/mnist-cnn-fpga/blob/main/deployment/DE1-SoC_Computer_15_640_current/verilog/layer4.sv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<!-- container: dark -->\n",
    "#### The Model\n",
    "Now that each layer is built, we need a module to instantiate the layers and expose to the top-level module (i.e. this is the module that gets instantiated in the DE1 SoC file).\n",
    "\n",
    "##### Verython Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python\n",
    "class Model(V_Target):\n",
    "    def __init__(\n",
    "        self,\n",
    "        int_width: BitWidth,\n",
    "        dec_width: BitWidth,\n",
    "        input_mem: M10K,\n",
    "        output_mem: M10K,\n",
    "        *specs: Iterable[LayerSpec]\n",
    "    ):\n",
    "\n",
    "        self.int_width = int_width\n",
    "        self.dec_width = dec_width\n",
    "        self.width = int_width + dec_width\n",
    "\n",
    "        assert self.width == input_mem.width and self.width == output_mem.width\n",
    "        assert len(specs) > 0\n",
    "\n",
    "        self.input_mem = input_mem\n",
    "        self.output_mem = output_mem\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self._configure_ports()\n",
    "\n",
    "        # ordered list of layers\n",
    "        self.layers: List[Layer] = []\n",
    "\n",
    "        # {Layer: (layer_cs, input_mem, output_mem)}\n",
    "        self.layer_map: Dict[Layer, Tuple[V_ConnSpec[Layer], M10K, M10K]] = {}\n",
    "\n",
    "        self.memories: Dict[M10K, V_ConnSpec[M10K]] = {\n",
    "            self.input_mem: V_ConnSpec[M10K](self,\n",
    "                                             self.input_mem,\n",
    "                                             prefix=\"input_mem\",\n",
    "                                             clk=self.clk,\n",
    "                                             reset=self.reset,\n",
    "                                             write_en=V_Empty(),\n",
    "                                             read_addr=self.inp_addr,\n",
    "                                             write_addr=V_Empty(),\n",
    "                                             read_data=self.inp_data,\n",
    "                                             write_data=V_Empty()\n",
    "                                             ),\n",
    "            self.output_mem: V_ConnSpec[M10K](self,\n",
    "                                              self.output_mem,\n",
    "                                              prefix=\"output_mem\",\n",
    "                                              clk=self.clk,\n",
    "                                              reset=self.reset,\n",
    "                                              write_en=self.out_we,\n",
    "                                              read_addr=V_Empty(),\n",
    "                                              write_addr=self.out_addr,\n",
    "                                              read_data=V_Empty(),\n",
    "                                              write_data=self.out_data\n",
    "                                              )\n",
    "        }\n",
    "\n",
    "        self._set_up_layers(*specs)\n",
    "\n",
    "        # set each layer reset flag to be a reg\n",
    "        for layer_cs, *_ in self.layer_map.values():\n",
    "            layer_cs.reset.dtype = V_Reg\n",
    "\n",
    "        # create each of the layer states\n",
    "        self.layer_states: List[Type[V_State]] = self._create_layer_states(0)\n",
    "\n",
    "    def generate(self) -> V_Block:\n",
    "        transition_memories = {mem: cs for mem, cs in self.memories.items()\n",
    "                               if mem not in [self.input_mem, self.output_mem]}\n",
    "\n",
    "        vsm = V_StateMachine(_StReset, _StWaitValid, *self.layer_states)\n",
    "\n",
    "        self.layer_ins = [layer.instantiate(\n",
    "            self, *cs) for layer, (cs, *_) in self.layer_map.items()]\n",
    "\n",
    "        return V_Block(\n",
    "            \"\\n// the model state machine\",\n",
    "            *vsm.generate(self, self.clk, self.reset, self.done),\n",
    "\n",
    "            \"\\n// instantiate the transition memories\",\n",
    "            *[line for mem, cs in transition_memories.items()\n",
    "              for line in mem(self, *cs)],\n",
    "\n",
    "            \"\\n// instantiate the layers\",\n",
    "            *[line for layer_ins in self.layer_ins for line in layer_ins]\n",
    "        )\n",
    "\n",
    "    def instantiate(\n",
    "        self,\n",
    "        instantiator: V_Module,\n",
    "        clk: V_Clock,\n",
    "        reset: V_Reset,\n",
    "        valid: V_Valid,\n",
    "        done: V_Done,\n",
    "        ready: V_Ready\n",
    "    ):\n",
    "        assert isinstance(instantiator, V_Module)\n",
    "        assert V_Clock.isinstance(clk)\n",
    "        assert V_Reset.isinstance(reset)\n",
    "        assert V_Valid.isinstance(valid)\n",
    "        assert V_Done.isinstance(done)\n",
    "        assert V_Ready.isinstance(ready)\n",
    "\n",
    "        port_connections = [\n",
    "            (clk, self.clk),\n",
    "            (reset, self.reset),\n",
    "            (valid, self.valid),\n",
    "            (done, self.done),\n",
    "            (ready, self.ready)\n",
    "        ]\n",
    "\n",
    "        inp_addr, inp_data = self.input_mem.read\n",
    "\n",
    "        assert instantiator.name in self.input_mem.connections, (\n",
    "            f\"{instantiator.name} has not instantiated {self.input_mem} yet.\")\n",
    "\n",
    "        connections = self.input_mem.connections[instantiator.name]\n",
    "        [addr_conn] = filter(lambda conn: conn.port is inp_addr,\n",
    "                             connections)\n",
    "        [data_conn] = filter(lambda conn: conn.port is inp_data,\n",
    "                             connections)\n",
    "\n",
    "        # save port connections\n",
    "        port_connections += [(addr_conn.var, self.inp_addr),\n",
    "                             (data_conn.var, self.inp_data)]\n",
    "\n",
    "        write_addr, write_data, write_en = self.output_mem.write\n",
    "\n",
    "        assert instantiator.name in self.output_mem.connections, (\n",
    "            f\"{instantiator.name} has not instantiated {self.output_mem} yet.\")\n",
    "\n",
    "        connections = self.output_mem.connections[instantiator.name]\n",
    "        [addr_conn] = filter(lambda conn: conn.port is write_addr,\n",
    "                             connections)\n",
    "        [data_conn] = filter(lambda conn: conn.port is write_data,\n",
    "                             connections)\n",
    "        [we_conn] = filter(lambda conn: conn.port is write_en,\n",
    "                           connections)\n",
    "\n",
    "        # save port connections\n",
    "        port_connections += [(addr_conn.var, self.out_addr),\n",
    "                             (data_conn.var, self.out_data),\n",
    "                             (we_conn.var, self.out_we)]\n",
    "\n",
    "        return super().instantiate(instantiator, *port_connections)\n",
    "\n",
    "    def _configure_ports(self):\n",
    "        \"\"\"\n",
    "        Creates all of the necessary ports.\n",
    "        \"\"\"\n",
    "\n",
    "        # configure the input ports\n",
    "        inp_addr, inp_data = self.input_mem.read\n",
    "\n",
    "        # create local copies\n",
    "        self.inp_addr = self.add_port(inp_addr,\n",
    "                                      port_type=V_Output,\n",
    "                                      dtype=V_Reg,\n",
    "                                      name=f\"inp_addr\")\n",
    "\n",
    "        self.inp_data = self.add_port(inp_data,\n",
    "                                      port_type=V_Input,\n",
    "                                      dtype=V_DType,\n",
    "                                      name=f\"inp_data\")\n",
    "\n",
    "        # configure the output ports\n",
    "        out_addr, out_data, out_we = self.output_mem.write\n",
    "\n",
    "        # create local copies\n",
    "        self.out_addr = self.add_port(out_addr,\n",
    "                                      port_type=V_Output,\n",
    "                                      dtype=V_Reg,\n",
    "                                      name=f\"out_addr\")\n",
    "\n",
    "        self.out_data = self.add_port(out_data,\n",
    "                                      port_type=V_Output,\n",
    "                                      dtype=V_Reg,\n",
    "                                      name=f\"out_data\")\n",
    "\n",
    "        self.out_we = self.add_port(out_we,\n",
    "                                    port_type=V_Output,\n",
    "                                    dtype=V_Reg,\n",
    "                                    name=f\"out_we\")\n",
    "\n",
    "    def _set_up_layers(self, *specs: Iterable[LayerSpec]) -> None:\n",
    "        \"\"\"\n",
    "        Sets up each layer with the appropriate input/output objects.\n",
    "        \"\"\"\n",
    "\n",
    "        # set initial I/O objects\n",
    "        input_mem, output_mem = self.input_mem, None\n",
    "\n",
    "        # create a list to hold the objects that need to get created\n",
    "        objects = list()\n",
    "\n",
    "        for i, (LayerT, weights_np, biases_np,\n",
    "                input_shape, output_shape) in enumerate(specs):\n",
    "            print(f\"Creating Layer: {LayerT}\")\n",
    "\n",
    "            input_size = np.prod(input_shape)\n",
    "            output_size = np.prod(output_shape)\n",
    "\n",
    "            assert_msg = f\"{input_mem} must have size of {input_size}\"\n",
    "            assert input_mem.size == input_size, assert_msg\n",
    "\n",
    "            # get the input mem conn spec\n",
    "            im_cs = self.memories[input_mem]\n",
    "\n",
    "            # skip last layer\n",
    "            if i + 1 == len(specs):\n",
    "                break\n",
    "\n",
    "            # create new output memory\n",
    "            output_mem = M10K(self.width, output_size, name=f\"trans_mem{i}\")\n",
    "\n",
    "            # add output memory to `objects` so it's generated\n",
    "            objects.append(output_mem)\n",
    "\n",
    "            # create layer object\n",
    "            layer: Layer = LayerT(int_width=self.int_width,\n",
    "                                  dec_width=self.dec_width,\n",
    "                                  weights_np=weights_np,\n",
    "                                  biases_np=biases_np,\n",
    "                                  input_mem=input_mem,\n",
    "                                  output_mem=output_mem,\n",
    "                                  input_shape=input_shape,\n",
    "                                  output_shape=output_shape)\n",
    "\n",
    "            # create the output mem conn spec\n",
    "            om_cs = V_ConnSpec[M10K](\n",
    "                self,\n",
    "                output_mem,\n",
    "                prefix=output_mem.name,\n",
    "                clk=self.clk,\n",
    "                reset=self.reset\n",
    "            )\n",
    "\n",
    "            layer_cs = V_ConnSpec[Layer](self,\n",
    "                                         layer,\n",
    "                                         prefix=layer.name,\n",
    "                                         clk=self.clk,\n",
    "                                         inp_addr=im_cs.read_addr,\n",
    "                                         inp_data=im_cs.read_data,\n",
    "                                         out_addr=om_cs.write_addr,\n",
    "                                         out_data=om_cs.write_data,\n",
    "                                         out_we=om_cs.write_en)\n",
    "\n",
    "            # adjust layer cs local variable dtypes\n",
    "            layer_cs.valid.dtype = V_Reg\n",
    "\n",
    "            # get layer file writer\n",
    "            layer_file = layer.tofile(f\"layer{i + 1}\")\n",
    "\n",
    "            # include layer\n",
    "            self.include(layer_file)\n",
    "\n",
    "            # store the output mem conn spec\n",
    "            self.memories[output_mem] = om_cs\n",
    "\n",
    "            # add layer instance to list\n",
    "            self.layers.append(layer)\n",
    "\n",
    "            # store an association between the layer and it's I/O memories\n",
    "            self.layer_map[layer] = (layer_cs, input_mem, output_mem)\n",
    "\n",
    "            # update input memory\n",
    "            input_mem = output_mem\n",
    "\n",
    "        ###############\n",
    "\n",
    "        # set the objects field of `self`\n",
    "        self._objects = objects\n",
    "\n",
    "        # get the conn spec of the output memory\n",
    "        om_cs = self.memories[self.output_mem]\n",
    "\n",
    "        # create the last layer\n",
    "        layer: Layer = LayerT(int_width=self.int_width,\n",
    "                              dec_width=self.dec_width,\n",
    "                              weights_np=weights_np,\n",
    "                              biases_np=biases_np,\n",
    "                              input_mem=input_mem,\n",
    "                              output_mem=self.output_mem,\n",
    "                              input_shape=input_shape,\n",
    "                              output_shape=output_shape)\n",
    "\n",
    "        # create the last conn spec\n",
    "        layer_cs = V_ConnSpec[Layer](self,\n",
    "                                     layer,\n",
    "                                     prefix=layer.name,\n",
    "                                     clk=self.clk,\n",
    "                                     inp_addr=im_cs.read_addr,\n",
    "                                     inp_data=im_cs.read_data,\n",
    "                                     out_addr=om_cs.write_addr,\n",
    "                                     out_data=om_cs.write_data,\n",
    "                                     out_we=om_cs.write_en)\n",
    "\n",
    "        # adjust layer cs local variable dtypes\n",
    "        layer_cs.valid.dtype = V_Reg\n",
    "\n",
    "        # add last layer instance to list\n",
    "        self.layers.append(layer)\n",
    "\n",
    "        # store last association between the layer and it's I/O memories\n",
    "        self.layer_map[layer] = (layer_cs, input_mem, output_mem)\n",
    "\n",
    "        # get layer file writer of last layer\n",
    "        layer_file = layer.tofile(f\"layer{i + 1}\")\n",
    "\n",
    "        # include last layer\n",
    "        self.include(layer_file)\n",
    "\n",
    "    def _create_layer_states(self, i) -> List[Type[V_State]]:\n",
    "\n",
    "        def generate(self, m: Model) -> V_Block:\n",
    "            \"\"\"\n",
    "            clear layer valid\n",
    "            if (layer done)\n",
    "                clear next layer reset\n",
    "                set next layer valid\n",
    "\n",
    "                go to next layer state or st done\n",
    "            \"\"\"\n",
    "\n",
    "            layer = m.layers[i]\n",
    "            layer_cs, *_ = m.layer_map[layer]\n",
    "\n",
    "            if i == len(m.layers) - 1:\n",
    "                block = V_Block(V_StDone)\n",
    "            else:\n",
    "                next_layer = m.layers[i + 1]\n",
    "                next_layer_cs, *_ = m.layer_map[next_layer]\n",
    "\n",
    "                block = V_Block(\n",
    "                    next_layer_cs.reset.set(V_Low),\n",
    "                    next_layer_cs.valid.set(V_High),\n",
    "                    m.layer_states[i + 1]\n",
    "                )\n",
    "\n",
    "            return V_Block(\n",
    "                layer_cs.valid.set(V_Low),\n",
    "                *V_If(layer_cs.done)(\n",
    "                    *block\n",
    "                )\n",
    "            )\n",
    "\n",
    "        st = type(f\"_StWaitLayer{i + 1}Done\",\n",
    "                  (V_State, ), {\"generate\": generate})\n",
    "\n",
    "        if i == len(self.layers) - 1:\n",
    "            return [st]\n",
    "\n",
    "        return [st] + self._create_layer_states(i + 1)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Model State Machine:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class _StReset(V_State):\n",
    "    \"\"\"\n",
    "    set each layer reset\n",
    "    clear each layer valid\n",
    "\n",
    "    go to StWaitValid\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Model) -> V_Block:\n",
    "\n",
    "        return V_Block(\n",
    "            *[cs.reset.set(V_High) for cs, *_ in m.layer_map.values()],\n",
    "            *[cs.valid.set(V_Low) for cs, *_ in m.layer_map.values()],\n",
    "\n",
    "            _StWaitValid\n",
    "        )\n",
    "\n",
    "\n",
    "class _StWaitValid(V_State):\n",
    "    \"\"\"\n",
    "    if (valid)\n",
    "        clear layer1 reset\n",
    "        set layer1 valid\n",
    "\n",
    "        go StWaitLayer1Done\n",
    "    \"\"\"\n",
    "\n",
    "    def generate(self, m: Model) -> V_Block:\n",
    "        assert len(m.layer_states) > 0\n",
    "\n",
    "        layer1 = m.layers[0]\n",
    "        layer_cs, *_ = m.layer_map[layer1]\n",
    "\n",
    "        return V_Block(\n",
    "            *V_If(m.valid)(\n",
    "                layer_cs.reset.set(V_Low),\n",
    "                layer_cs.valid.set(V_High),\n",
    "\n",
    "                m.layer_states[0]\n",
    "            )\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated Verilog: [Model](https://github.com/jfw225/mnist-cnn-fpga/blob/main/deployment/DE1-SoC_Computer_15_640_current/verilog/model.sv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<!-- container: default -->\n",
    "## Results and Conclusions\n",
    "Ultimately, we are really happy with the outcome of the project. There were essentially two parts of the project: training a good model and putting our model on the FPGA. The latter we were able to test emperically using ***Verython***. We built a feature that calculated the mean squared error between the expected output and the output of our Verilog code. We found that our verilog output differs by about $10^{-3}$ from the output of our Python model. And to be clear, this gives no indication as to how well our model can classify images of digits. That number simply says that our Verilog implementation was about $\\frac{1}{1000}$ off from the value that we would have computed if the same operations were performed on desktop computer. With that being said, the precision that we observed is more than enough for our FPGA implementation to match the digit classification of the Python implementation 99.99% of the time.\n",
    "\n",
    "That's all to say that if you drew a six, the Python model predicted a zero, and the FPGA predicted a zero, we would be ecstatic. However, Kenneth Trinh (klt45) managed to train an extremely accurate model as well. So not only is there very little precision lost on the FPGA, the FPGA is able to accurately classify drawings of digits. So yeah, I'd say we are pretty happy with the result. Here is a short clip of Dr. Adams testing out the system:\n",
    "![video][hunter drawing inputs](https://www.youtube.com/watch?v=ZbLdQtHRYA0)\n",
    "\n",
    "The entire project was inspired, designed, and developed, by our team. And even though the specific model that we trained might not be widely applicable, ***Verython*** can be used to tackle a wide variety of problems. That is why shortly after we turn in this project, we are going to add ***Verython*** to the PyPi repository and make it open-source. Our hope is that we can make the library robust enough to make high performance computing more accessible to everyone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Appendix\n",
    "\n",
    "### Appendix A\n",
    "\n",
    "The group approves this report for inclusion on the course website.\n",
    "\n",
    "The group approves the video for inclusion on the course YouTube channel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Appendix B: Verython\n",
    "***[Verython](https://github.com/jfw225/verython)*** (portmanteau of Verilog and Python pronounced \"verithon\").\n",
    "\n",
    "##### Verython Types\n",
    "[V_Types](https://github.com/jfw225/mnist-cnn-fpga/blob/main/src/python/verilog/core/vtypes.py)\n",
    "\n",
    "##### Verython Syntax\n",
    "[V_Syntax](https://github.com/jfw225/mnist-cnn-fpga/blob/main/src/python/verilog/core/vsyntax.py)\n",
    "\n",
    "##### Verython Objects\n",
    "[V_Objects](https://github.com/jfw225/mnist-cnn-fpga/blob/main/src/python/verilog/core/vsyntax.py)\n",
    "\n",
    "##### Verython Modules\n",
    "[V_Module](https://github.com/jfw225/mnist-cnn-fpga/blob/main/src/python/verilog/core/vmodule.py)\n",
    "[V_Iterable](https://github.com/jfw225/mnist-cnn-fpga/blob/main/src/python/verilog/core/viterable.py)\n",
    "[V_Target](https://github.com/jfw225/mnist-cnn-fpga/blob/main/src/python/verilog/core/vtarget.py)\n",
    "\n",
    "##### Verython States and State Machines\n",
    "[V_State and V_StateMachine](https://github.com/jfw225/mnist-cnn-fpga/blob/main/src/python/verilog/core/vstate.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Appendix C\n",
    "[Comparison of deep learning and human observer performance for detection and characterization of simulated lesions](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6586983/)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
